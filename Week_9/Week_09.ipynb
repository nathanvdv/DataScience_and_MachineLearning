{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/michalis0/DataScience_and_MachineLearning/blob/master/Week_9/Week_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "rg25MkDgcADy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install langchain\n",
        "!pip install wikipedia\n",
        "!pip install chromadb\n",
        "!pip install tiktoken\n",
        "!pip install pypdf\n",
        "!pip install faiss-gpu"
      ],
      "metadata": {
        "id": "lLbG_J_EdcyH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xeaa6cWTeWOI",
        "outputId": "f7bf4849-7c34-46e7-d9dc-5f3c5211225d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28.1 in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NCfM18ZRl8L"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wikipedia\n",
        "import urllib.request\n",
        "import bs4 as bs\n",
        "import os\n",
        "\n",
        "#import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# import Langchain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.callbacks import get_openai_callback\n",
        "from langchain.chains import create_tagging_chain, create_tagging_chain_pydantic\n",
        "from langchain.vectorstores import FAISS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5WgfVqRRl8N"
      },
      "source": [
        "# Generative AI\n",
        "\n",
        "<img src='https://images.unsplash.com/photo-1686191568035-db49125b65c6?auto=format&fit=crop&q=80&w=2940&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D' width=\"450\">\n",
        "\n",
        "Credit: [Mojahid Mottakin](https://unsplash.com/@iammottakin)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onO46LysT2dh"
      },
      "source": [
        "## Content\n",
        "\n",
        "The goal of this walkthrough is to provide you with insights on [Generative AI](https://en.wikipedia.org/wiki/Generative_artificial_intelligence). Generative AI refers to artificial intelligence systems that can create new and original content, such as text, images, or music, without direct human input.\n",
        "\n",
        "We will first see some applications that we can have with GenAI and the text. We will also see that using GenAI can be costly and we will finally try to fine tune a model.\n",
        "\n",
        "- [First steps with LangChain and OpenAI](#First-steps)\n",
        "    - [Claculate the cost](#Cost)\n",
        "- [Text Summarization](#Text-Summarization)\n",
        "- [Sentiment analysis](#Sentiment-analysis)\n",
        "- [Text embedding](#Text-embedding)\n",
        "- [Fine-tuning](#Fine-tuning)\n",
        "- [Your turn!](#exercices)\n",
        "    - [Prompt](#prompting)\n",
        "    - [Summarizing](#Summarizing)\n",
        "    - [Sentiment analysis](#Sentiment-analysis-ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First steps with LangChain and OpenAI\n",
        "During this exercise session, we will be using the [OpenAI](https://platform.openai.com/docs/api-reference) API with different libraries.\n",
        "First we will need to setup the apikey and some of the librairies.\n",
        "\n",
        "Due to recent changes in the openAI library, there are incompatibilities with the Langchain library. We will therfore use a previous version by using this command:\n",
        "\n",
        "```\n",
        "!pip install openai==0.28.1\n",
        "```\n",
        "We will also use the [Langchain](https://python.langchain.com/docs/get_started/introduction) library for the prompting and the text applications.\n",
        "\n",
        "First, we will define the API key. (This key usually has a price, but it has been given by prof. Vlachos for this week so that you can play with it."
      ],
      "metadata": {
        "id": "Jv1T75j9YpS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the openAI API key\n",
        "os.environ['OPENAI_API_KEY'] = ''\n",
        "print(os.getenv('OPENAI_API_KEY'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNtXBIJGbB1Q",
        "outputId": "21aa497f-9928-47c8-ea81-df4b42f6ed50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To try the key, let's use ChatOpenAI like we would use ChatGPT. To do so, we will need to import the ChatOpenAI model:\n",
        "\n",
        "\n",
        "```\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "M_A3akTUhHCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the chat and try it with a simple message\n",
        "chat_model  = ChatOpenAI()\n",
        "llm = OpenAI()\n",
        "\n",
        "print(llm.predict(\"Hi! How are you?\"))\n",
        "print(chat_model.predict(\"Hi! How are you?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aFDzxmgYsdD",
        "outputId": "e2b48742-5300-4b4c-9e00-2d9e2dc689ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "I'm doing well, thank you. How about you?\n",
            "Hello! As an AI language model, I don't have feelings, but I'm here to help you. How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also use it differently as it is shown in the two following examples."
      ],
      "metadata": {
        "id": "TmORZnjrl15m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What would be a good startup name for startup from a student who just graduated from a degree in Information Systems and Digital Innovation?\"\n",
        "\n",
        "print(llm.predict(text))\n",
        "print(chat_model.predict(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTeJiGm6iNtl",
        "outputId": "01848b4e-1e82-4b04-cb4f-9d25e9477837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "InnoSysTech Solutions\n",
            "1. DataTech Solutions\n",
            "2. DigitalEdge Innovations\n",
            "3. InfoSys Solutions\n",
            "4. TechGenius Innovations\n",
            "5. ByteLaunch Technologies\n",
            "6. InnovateIT Systems\n",
            "7. DigitalSphere Solutions\n",
            "8. InfoInnovate\n",
            "9. DataDriven Tech\n",
            "10. GradTech Solutions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What would be a good startup name for startup from a student who just graduated from a degree in Information Systems and Digital Innovation?\"\n",
        "messages = [HumanMessage(content=text)]\n",
        "\n",
        "print(llm.predict_messages(messages).content)\n",
        "print(chat_model.predict_messages(messages).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXde7hOAiaVw",
        "outputId": "7de891ce-2621-4762-86be-d2d0cec1c138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Answer: DigiGrow Solutions.\n",
            "1. TechEdge Solutions\n",
            "2. Innovista Tech\n",
            "3. Cybertech Labs\n",
            "4. InfoSys Innovators\n",
            "5. Digitech Ventures\n",
            "6. CodeGenius\n",
            "7. DataTech Solutions\n",
            "8. Infopreneur Labs\n",
            "9. Digital Nexus\n",
            "10. Techno Innovators\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With Langchain, you can directly pass specifications for a prompt by using the ```PromptTemplate``` module."
      ],
      "metadata": {
        "id": "1YqxMiZcmOxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate.from_template(\"What is a good name for a startup that works in {field}?\")\n",
        "prompt.format(field=\"Information Systems and Digital Innovation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8bxWPF9mkoyI",
        "outputId": "8be74645-b87a-4b7f-dc8f-714402e7d40b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is a good name for a startup that works in Information Systems and Digital Innovation?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate the cost\n",
        "Everything as a cost and the chatGPT API is not free. It depends on how many tokens we are giving to the API. You can have the pricing [here](https://openai.com/pricing).\n",
        "\n",
        "To give you an idea of the costs, calculate the price of using the GPT-4 model with a document that contains 86'000 tokens and you want a summary of 1'000 tokens."
      ],
      "metadata": {
        "id": "ti0RqVq8_Fzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your turn!\n",
        "tokens_input =\n",
        "tokens_output =\n",
        "cost_per_token_input =\n",
        "cost_per_token_output =\n",
        "total_cost =\n"
      ],
      "metadata": {
        "id": "JPrLNLh69NNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Summarization\n",
        "GenerativeAI can be very useful to summarize data. We will continue to use [Langchain](https://python.langchain.com/docs/use_cases/summarization) for our implementation. We will try to summarize the Wikipedia page of [*Information System*](https://en.wikipedia.org/wiki/Information_system). We will first load the text, the model [gpt-3.5-turbo-16k](https://platform.openai.com/docs/models/gpt-3-5), which allow us to have 16k tokens, and the chain."
      ],
      "metadata": {
        "id": "-pI-k5OMvn95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the text\n",
        "loader = WebBaseLoader(\"https://en.wikipedia.org/wiki/Information_system\")\n",
        "docs = loader.load()\n",
        "\n",
        "# load the model and the chain\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-16k-0613\")\n",
        "chain = load_summarize_chain(llm, chain_type=\"stuff\")"
      ],
      "metadata": {
        "id": "XyaUfkbNvpvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate the cost\n",
        "Using openAI API is not free. You can calculate the cost of your model like this:\n"
      ],
      "metadata": {
        "id": "Nl9w98ej_Nhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get the costs\n",
        "with get_openai_callback() as cb:\n",
        "  result = chain.run(docs)\n",
        "  print(cb)\n",
        "  display(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "yBCYdOpk_gIT",
        "outputId": "8a185036-4684-4a31-8411-fb74de52a6b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens Used: 11483\n",
            "\tPrompt Tokens: 11316\n",
            "\tCompletion Tokens: 167\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.03461600000000001\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'An information system is a formal, sociotechnical, organizational system designed to collect, process, store, and distribute information. It consists of hardware, software, data, procedures, and people. Information systems can support business decisions, and they are also studied as an academic discipline. There are various types of information systems, such as transaction processing systems, decision support systems, and enterprise systems. Information systems play a crucial role in organizations and can support operations, management, and decision-making. The field of information systems encompasses topics such as systems analysis and design, computer networking, information security, and database management. Career pathways in information systems include roles in strategy, management, consulting, security, and auditing. Research in information systems focuses on the effects of information systems on individuals, groups, and organizations, and it can be interdisciplinary in nature.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment analysis\n",
        "\n",
        "By using Langchain, we can also classify the text. You can give different categories to the model and it will try to classify the sentence. For example, we will do a sentiment analysis and we will try to recognize in which language it is written.\n"
      ],
      "metadata": {
        "id": "VsQoyYkH1lwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Schema\n",
        "schema = {\n",
        "    \"properties\": {\n",
        "        \"sentiment\": {\n",
        "            \"type\": \"string\",\n",
        "            \"enum\":[\"positive\", \"neutral\", \"negative\"],\n",
        "        },\n",
        "        \"language\": {\n",
        "            \"type\": \"string\",\n",
        "            \"enum\": [\"spanish\", \"english\", \"french\", \"german\", \"italian\"],\n",
        "        },\n",
        "    },\n",
        "    \"required\": [\"sentiment\", \"language\"],\n",
        "}\n",
        "\n",
        "# LLM\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")\n",
        "chain = create_tagging_chain(schema, llm)"
      ],
      "metadata": {
        "id": "DI6x1BhRJPHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "input = \"I love dogs!\"\n",
        "\n",
        "chain.run(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlb1g9BWO5KS",
        "outputId": "91f19d72-4d04-4863-8373-12567c47ce39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentiment': 'positive', 'language': 'english'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text embedding\n",
        "LangChain is also useful for text embedding. You can see the different models [here](https://python.langchain.com/docs/integrations/text_embedding/). You can have a look at the natural language processing class if you don't remeber why text embedding is important.\n",
        "\n",
        "You can either do the text embedding for a list of texts or a single piece of text."
      ],
      "metadata": {
        "id": "R_SUKEgOSnOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "3AwioZxzZz4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#embeding a single query\n",
        "text = \"This is a test document.\"\n",
        "query_result = embeddings.embed_query(text)\n",
        "query_result[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55i2zcA2YW3s",
        "outputId": "71353e9f-0ef4-4ad2-81eb-a0d4777f78a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.003105442842703499,\n",
              " 0.011136301333111021,\n",
              " -0.004029582553785511,\n",
              " -0.01174906406444312,\n",
              " -0.0010406979861090607]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#embeding a list of texts\n",
        "embedds = embeddings.embed_documents(\n",
        "    [\n",
        "        \"Hi there!\",\n",
        "        \"Oh, hello!\",\n",
        "        \"What's your name?\",\n",
        "        \"My friends call me World\",\n",
        "        \"Hello World!\"\n",
        "    ]\n",
        ")\n",
        "len(embedds), len(embedds[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w89IGJ2IZ2eo",
        "outputId": "c8014877-6600-4c81-f934-72ca1eaa74a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1536)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning\n",
        "\n",
        "Fine-tuning refers to the process of taking a pre-trained model (like chatGPT) and further training it on a specific task or dataset to improve its performance on that particular task. Instead of training a model from scratch, which can be computationally expensive and time-consuming, fine-tuning leverages the knowledge and features learned by a model on a large and diverse dataset.\n",
        "\n",
        "You can have a more detailed article [here](https://medium.com/@dataoilst.info/fine-tuning-langchain-llm-applications-a-technical-perspective-part-1-4b4c552ab557).\n",
        "\n",
        "For now, we will use the previous text and try to ask the model a question."
      ],
      "metadata": {
        "id": "dZ-TviJxmMsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#processing the document\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(docs)\n",
        "embeddings = OpenAIEmbeddings()\n",
        "db = FAISS.from_documents(texts, embeddings)\n",
        "retriever = db.as_retriever()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F82FIQoZatwK",
        "outputId": "7766df47-1b61-459c-fb00-9a80234fae3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 3652, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1389, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2112, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2441, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1599, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1921, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2605, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2020, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 3724, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1616, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 3163, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1153, which is longer than the specified 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#asking the question\n",
        "retrieved_docs = retriever.invoke(\n",
        "    \"What is an information system?\"\n",
        ")\n",
        "print(retrieved_docs[0].page_content)"
      ],
      "metadata": {
        "id": "ZZimOCk4a9dD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fd7e7cc-4128-47e4-aa7b-2dba59da532a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System that supports business decisions\n",
            "\"Business Information System\" redirects here. For the Finnish government service, see YTJ (Finnish government service).\n",
            "An information system (IS) is a formal, sociotechnical, organizational system designed to collect, process, store, and distribute information.[1] From a sociotechnical perspective, information systems are composed by four components: task, people, structure (or roles), and technology.[2] Information systems can be defined as an integration of components for collection, storage and processing of data of which the data is used to provide information, contribute to knowledge as well as digital products that facilitate decision making.[3]\n",
            "Bachelor of Business Information Systems  BBIS[4]  is an Information Technology(IT) and management focused undergraduate program designed to better understand the needs of rapidly growing technology in business and IT sector.It is bachelor degree that combines elements of business administration and computer science with majoring on information systems and technology.The purpose of this course is to equip students with the skills and knowledge needed to effectively manage and utilize information technology in a business and IT industry.\n",
            "A computer information system is a system that is composed of people and computers that processes or interprets information.[5][6][7][8] The term is also sometimes used to simply refer to a computer system with software installed.\n",
            "\"Information systems\" is also an academic field study about systems with a specific reference to information and the complementary networks of computer hardware and software that people and organizations use to collect, filter, process, create and also distribute data.[9] An emphasis is placed on an information system having a definitive boundary, users, processors, storage, inputs, outputs and the aforementioned communication networks.[10]\n",
            "In many organizations, the department or unit responsible for information systems and data processing is known as \"information services\".[11][12][13][14]\n",
            "Any specific information system aims to support operations, management and decision-making.[15][16] An information system is the information and communication technology (ICT) that an organization uses, and also the way in which people interact with this technology in support of business processes.[17]\n",
            "Some authors make a clear distinction between information systems, computer systems, and business processes. Information systems typically include an ICT component but are not purely concerned with ICT, focusing instead on the end-use of information technology. Information systems are also different from business processes. Information systems help to control the performance of business processes.[18]\n",
            "Alter[19][20] argues for advantages of viewing an information system as a special type of work system. A work system is a system in which humans or machines perform processes and activities using resources to produce specific products or services for customers. An information system is a work system whose activities are devoted to capturing, transmitting, storing, retrieving, manipulating and displaying information.[21]\n",
            "As such, information systems inter-relate with data systems on the one hand and activity systems on the other.[22] An information system is a form of communication system in which data represent and are processed as a form of social memory. An information system can also be considered a semi-formal language which supports human decision making and action.\n",
            "Information systems are the primary focus of study for organizational informatics.[23]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the model is simply giving us the parts where information system is mentionned. Therfore, the model is not very useful. You can however go a bit further if you wish to integrate it better."
      ],
      "metadata": {
        "id": "lU4dqJmMeRYO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Your turn!"
      ],
      "metadata": {
        "id": "9owDlwBaLXp0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt\n",
        "Create a prompt to ask chatGPT some project ideas for a Data Science and Machine Learning class. Try to apply some rules of [prompt engineering](https://www.datacamp.com/tutorial/a-beginners-guide-to-chatgpt-prompt-engineering)."
      ],
      "metadata": {
        "id": "cDbF60XZevym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code"
      ],
      "metadata": {
        "id": "uFZ5t75WfMXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summarizing\n",
        "\n",
        "You will now try to summarize one of your lesson and print how much it costed by using the model ```gpt-3.5-turbo-16k-0613```. You might want to look at the package ```PyPDFLoader``` in order to load your pdf.\n",
        "\n"
      ],
      "metadata": {
        "id": "VAG2jjy_wGhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code\n"
      ],
      "metadata": {
        "id": "VAQQxguTyI9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentiment analysis\n",
        "Try to classify this sentence: ```J'aime l'intelligence artificielle.```"
      ],
      "metadata": {
        "id": "EPPhytTFRQNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code\n"
      ],
      "metadata": {
        "id": "OpKnsJ1BRhR7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}