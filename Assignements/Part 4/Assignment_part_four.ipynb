{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/michalis0/DataScience_and_MachineLearning/blob/master/Assignements/Part%204/Assignment_part_four.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZu-7QbP9muh"
   },
   "source": [
    "DSML investigation:\n",
    "\n",
    "You are part of the Suisse Impossible Mission Force, or SIMF for short. You need to uncover a rogue agent that is trying to steal sensitive information.\n",
    "\n",
    "Your mission, should you choose to accept it, is to find that agent before stealing any classified information. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyL7WNdV9sWV"
   },
   "source": [
    "# Assignement part four\n",
    "### Due 22.10\n",
    "#### Identifying the suspects credit score\n",
    "We received informations that the rogue agent has a good credit score.\n",
    "\n",
    "Our spies at SIMF have managed to collect financial information relating to our suspects as well as a training dataset.\n",
    "\n",
    "Create a Neural Network over the training dataset `df` to identify which of the suspects have a good Credit_Mix\n",
    "\n",
    "\n",
    "## Getting to know our data\n",
    "\n",
    "* Age: a users age\n",
    "* Occupation: a users employment field\n",
    "* Annual_Income: a users annual income\n",
    "* Monthly_Inh_Salary: the calculated salary received by a given user on a monthly basis\n",
    "* Num_Bank_Accounts: the number of bank accounts possessed by a given user\n",
    "* Num_Credit_Cards: the number of credit card given user possesses\n",
    "* Interest_Rate: The interest rate on those cards (if multiple then its the average)\n",
    "* Num_of_Loans: The number of loans of each user\n",
    "* Delay_from_due_date: payment tardiness of user\n",
    "* Num_of_Delayed_Payment: the count of delayed payments\n",
    "* Changed_Credit_Limit: NaN\n",
    "* Num_Credit_Inquiries: NaN\n",
    "* Credit_Mix: The users credit score\n",
    "* Outsting_Debt: Outstanding debt\n",
    "* Credit_Utilization_Ratio: the percentage of borrowed money over borrowing allowance\n",
    "* Payment_of_Min_Amount: does the user usually pay the minimal amount (categorical)\n",
    "* Total_EMI_per_month: Monthly repayments to be made\n",
    "* Amount_invested_monthly: The amout put in an investment fun by the user on a monthly basis\n",
    "* Payment_Behaviour: the users payment behavior (categorical)\n",
    "* Monthly_Balance: The users end of the month balance\n",
    "* AutoLoan: If the user has an active loan for their vehicule\n",
    "* Credit-BuilderLoan: If the user has a loan to increase their credit score\n",
    "* DebtConsolidationLoan, HomeEquityLoan, MortgageLoan, NotSpecified, PaydayLoan, PersonalLoan, StudentLoan: different types of loans(categorical features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XHhI95r5-tyD"
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/michalis0/DataScience_and_MachineLearning/master/Assignements/Part%204/data/train_classification.csv\", index_col='Unnamed: 0').dropna()\n",
    "suspects = pd.read_csv(\"https://raw.githubusercontent.com/michalis0/DataScience_and_MachineLearning/master/Assignements/Part%204/data/suspects.csv\", index_col='Unnamed: 0').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 29223 entries, 0 to 49998\n",
      "Data columns (total 29 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Age                       29223 non-null  int64  \n",
      " 1   Occupation                29223 non-null  object \n",
      " 2   Annual_Income             29223 non-null  float64\n",
      " 3   Monthly_Inh_Salary        29223 non-null  float64\n",
      " 4   Num_Bank_Accounts         29223 non-null  int64  \n",
      " 5   Num_Credit_Card           29223 non-null  int64  \n",
      " 6   Interest_Rate             29223 non-null  int64  \n",
      " 7   Num_of_Loan               29223 non-null  int64  \n",
      " 8   Delay_from_due_date       29223 non-null  int64  \n",
      " 9   Num_of_Delayed_Payment    29223 non-null  int64  \n",
      " 10  Changed_Credit_Limit      29223 non-null  float64\n",
      " 11  Num_Credit_Inquiries      29223 non-null  float64\n",
      " 12  Credit_Mix                29223 non-null  object \n",
      " 13  Outsting_Debt             29223 non-null  float64\n",
      " 14  Credit_Utilization_Ratio  29223 non-null  float64\n",
      " 15  Payment_of_Min_Amount     29223 non-null  object \n",
      " 16  Total_EMI_per_month       29223 non-null  float64\n",
      " 17  Amount_invested_monthly   29223 non-null  float64\n",
      " 18  Payment_Behaviour         29223 non-null  object \n",
      " 19  Monthly_Balance           29223 non-null  float64\n",
      " 20  AutoLoan                  29223 non-null  int64  \n",
      " 21  Credit-BuilderLoan        29223 non-null  int64  \n",
      " 22  DebtConsolidationLoan     29223 non-null  int64  \n",
      " 23  HomeEquityLoan            29223 non-null  int64  \n",
      " 24  MortgageLoan              29223 non-null  int64  \n",
      " 25  NotSpecified              29223 non-null  int64  \n",
      " 26  PaydayLoan                29223 non-null  int64  \n",
      " 27  PersonalLoan              29223 non-null  int64  \n",
      " 28  StudentLoan               29223 non-null  int64  \n",
      "dtypes: float64(9), int64(16), object(4)\n",
      "memory usage: 6.7+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 714 entries, 0 to 1237\n",
      "Data columns (total 43 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Age                       714 non-null    float64\n",
      " 1   Annual_Income             714 non-null    float64\n",
      " 2   Monthly_Inh_Salary        714 non-null    float64\n",
      " 3   Num_Bank_Accounts         714 non-null    float64\n",
      " 4   Num_Credit_Card           714 non-null    float64\n",
      " 5   Interest_Rate             714 non-null    float64\n",
      " 6   Num_of_Loan               714 non-null    float64\n",
      " 7   Delay_from_due_date       714 non-null    float64\n",
      " 8   Num_of_Delayed_Payment    714 non-null    float64\n",
      " 9   Changed_Credit_Limit      714 non-null    float64\n",
      " 10  Num_Credit_Inquiries      714 non-null    float64\n",
      " 11  Outsting_Debt             714 non-null    float64\n",
      " 12  Credit_Utilization_Ratio  714 non-null    float64\n",
      " 13  Payment_of_Min_Amount     714 non-null    int64  \n",
      " 14  Total_EMI_per_month       714 non-null    float64\n",
      " 15  Amount_invested_monthly   714 non-null    float64\n",
      " 16  Payment_Behaviour         714 non-null    int64  \n",
      " 17  Monthly_Balance           714 non-null    float64\n",
      " 18  AutoLoan                  714 non-null    float64\n",
      " 19  Credit-BuilderLoan        714 non-null    float64\n",
      " 20  DebtConsolidationLoan     714 non-null    float64\n",
      " 21  HomeEquityLoan            714 non-null    float64\n",
      " 22  MortgageLoan              714 non-null    float64\n",
      " 23  NotSpecified              714 non-null    float64\n",
      " 24  PaydayLoan                714 non-null    float64\n",
      " 25  PersonalLoan              714 non-null    float64\n",
      " 26  StudentLoan               714 non-null    float64\n",
      " 27  Occupation_Accountant     714 non-null    float64\n",
      " 28  Occupation_Architect      714 non-null    float64\n",
      " 29  Occupation_Developer      714 non-null    float64\n",
      " 30  Occupation_Doctor         714 non-null    float64\n",
      " 31  Occupation_Engineer       714 non-null    float64\n",
      " 32  Occupation_Entrepreneur   714 non-null    float64\n",
      " 33  Occupation_Journalist     714 non-null    float64\n",
      " 34  Occupation_Lawyer         714 non-null    float64\n",
      " 35  Occupation_Manager        714 non-null    float64\n",
      " 36  Occupation_Mechanic       714 non-null    float64\n",
      " 37  Occupation_MediaManager   714 non-null    float64\n",
      " 38  Occupation_Musician       714 non-null    float64\n",
      " 39  Occupation_Scientist      714 non-null    float64\n",
      " 40  Occupation_Teacher        714 non-null    float64\n",
      " 41  Occupation_Writer         714 non-null    float64\n",
      " 42  userID                    714 non-null    int64  \n",
      "dtypes: float64(40), int64(3)\n",
      "memory usage: 245.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "suspects.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Credit_Mix\n",
       "Standard    13421\n",
       "Good         8963\n",
       "Bad          6839\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Credit_Mix\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZENObtyefVk"
   },
   "source": [
    "# 1. Preparing the data\n",
    "## 1.1 Data cleaning\n",
    " Perform OHE over the \"Occupation\" feature\n",
    "\n",
    " Then, perform LE over Payment_of_Min_Amount and Payment_Behaviour\n",
    "\n",
    " _hint: As we will be testing only one model no need to define a pipeline_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JGVrLNJTefVk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Annual_Income  Monthly_Inh_Salary  Num_Bank_Accounts  Num_Credit_Card  \\\n",
      "0   23       19114.12         1824.843333                  3                4   \n",
      "1   24       19114.12         1824.843333                  3                4   \n",
      "3   24       19114.12         4182.004291                  3                4   \n",
      "5   28       34847.84         3037.986667                  2                4   \n",
      "8   35      143162.64         4182.004291                  1                5   \n",
      "\n",
      "   Interest_Rate  Num_of_Loan  Delay_from_due_date  Num_of_Delayed_Payment  \\\n",
      "0              3            4                    3                       7   \n",
      "1              3            4                    3                       9   \n",
      "3              3            4                    4                       5   \n",
      "5              6            1                    3                       3   \n",
      "8              8            3                    8                    1942   \n",
      "\n",
      "   Changed_Credit_Limit  ...  Occupation_Entrepreneur Occupation_Journalist  \\\n",
      "0                 11.27  ...                      0.0                   0.0   \n",
      "1                 13.27  ...                      0.0                   0.0   \n",
      "3                 11.27  ...                      0.0                   0.0   \n",
      "5                  5.42  ...                      0.0                   0.0   \n",
      "8                  7.10  ...                      0.0                   0.0   \n",
      "\n",
      "   Occupation_Lawyer  Occupation_Manager Occupation_Mechanic  \\\n",
      "0                0.0                 0.0                 0.0   \n",
      "1                0.0                 0.0                 0.0   \n",
      "3                0.0                 0.0                 0.0   \n",
      "5                0.0                 0.0                 0.0   \n",
      "8                0.0                 0.0                 0.0   \n",
      "\n",
      "   Occupation_MediaManager  Occupation_Musician Occupation_Scientist  \\\n",
      "0                      0.0                  0.0                  1.0   \n",
      "1                      0.0                  0.0                  1.0   \n",
      "3                      0.0                  0.0                  1.0   \n",
      "5                      0.0                  0.0                  0.0   \n",
      "8                      0.0                  0.0                  0.0   \n",
      "\n",
      "   Occupation_Teacher  Occupation_Writer  \n",
      "0                 0.0                0.0  \n",
      "1                 0.0                0.0  \n",
      "3                 0.0                0.0  \n",
      "5                 1.0                0.0  \n",
      "8                 0.0                0.0  \n",
      "\n",
      "[5 rows x 43 columns]\n",
      "0         No\n",
      "1         No\n",
      "3         No\n",
      "5         No\n",
      "8         No\n",
      "        ... \n",
      "49990     No\n",
      "49992    Yes\n",
      "49993    Yes\n",
      "49997     No\n",
      "49998     No\n",
      "Name: Payment_of_Min_Amount, Length: 29223, dtype: object 0          LowspentSmallvaluepayments\n",
      "1        HighspentMediumvaluepayments\n",
      "3        HighspentMediumvaluepayments\n",
      "5          LowspentLargevaluepayments\n",
      "8         LowspentMediumvaluepayments\n",
      "                     ...             \n",
      "49990      LowspentLargevaluepayments\n",
      "49992      LowspentSmallvaluepayments\n",
      "49993      LowspentSmallvaluepayments\n",
      "49997      LowspentLargevaluepayments\n",
      "49998     HighspentSmallvaluepayments\n",
      "Name: Payment_Behaviour, Length: 29223, dtype: object\n",
      "0        1\n",
      "1        1\n",
      "3        1\n",
      "5        1\n",
      "8        1\n",
      "        ..\n",
      "49990    1\n",
      "49992    2\n",
      "49993    2\n",
      "49997    1\n",
      "49998    1\n",
      "Name: Payment_of_Min_Amount, Length: 29223, dtype: int64 0        6\n",
      "1        2\n",
      "3        2\n",
      "5        4\n",
      "8        5\n",
      "        ..\n",
      "49990    4\n",
      "49992    6\n",
      "49993    6\n",
      "49997    4\n",
      "49998    3\n",
      "Name: Payment_Behaviour, Length: 29223, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 29223 entries, 0 to 49998\n",
      "Data columns (total 43 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Age                       29223 non-null  int64  \n",
      " 1   Annual_Income             29223 non-null  float64\n",
      " 2   Monthly_Inh_Salary        29223 non-null  float64\n",
      " 3   Num_Bank_Accounts         29223 non-null  int64  \n",
      " 4   Num_Credit_Card           29223 non-null  int64  \n",
      " 5   Interest_Rate             29223 non-null  int64  \n",
      " 6   Num_of_Loan               29223 non-null  int64  \n",
      " 7   Delay_from_due_date       29223 non-null  int64  \n",
      " 8   Num_of_Delayed_Payment    29223 non-null  int64  \n",
      " 9   Changed_Credit_Limit      29223 non-null  float64\n",
      " 10  Num_Credit_Inquiries      29223 non-null  float64\n",
      " 11  Credit_Mix                29223 non-null  object \n",
      " 12  Outsting_Debt             29223 non-null  float64\n",
      " 13  Credit_Utilization_Ratio  29223 non-null  float64\n",
      " 14  Payment_of_Min_Amount     29223 non-null  int64  \n",
      " 15  Total_EMI_per_month       29223 non-null  float64\n",
      " 16  Amount_invested_monthly   29223 non-null  float64\n",
      " 17  Payment_Behaviour         29223 non-null  int64  \n",
      " 18  Monthly_Balance           29223 non-null  float64\n",
      " 19  AutoLoan                  29223 non-null  int64  \n",
      " 20  Credit-BuilderLoan        29223 non-null  int64  \n",
      " 21  DebtConsolidationLoan     29223 non-null  int64  \n",
      " 22  HomeEquityLoan            29223 non-null  int64  \n",
      " 23  MortgageLoan              29223 non-null  int64  \n",
      " 24  NotSpecified              29223 non-null  int64  \n",
      " 25  PaydayLoan                29223 non-null  int64  \n",
      " 26  PersonalLoan              29223 non-null  int64  \n",
      " 27  StudentLoan               29223 non-null  int64  \n",
      " 28  Occupation_Accountant     29223 non-null  float64\n",
      " 29  Occupation_Architect      29223 non-null  float64\n",
      " 30  Occupation_Developer      29223 non-null  float64\n",
      " 31  Occupation_Doctor         29223 non-null  float64\n",
      " 32  Occupation_Engineer       29223 non-null  float64\n",
      " 33  Occupation_Entrepreneur   29223 non-null  float64\n",
      " 34  Occupation_Journalist     29223 non-null  float64\n",
      " 35  Occupation_Lawyer         29223 non-null  float64\n",
      " 36  Occupation_Manager        29223 non-null  float64\n",
      " 37  Occupation_Mechanic       29223 non-null  float64\n",
      " 38  Occupation_MediaManager   29223 non-null  float64\n",
      " 39  Occupation_Musician       29223 non-null  float64\n",
      " 40  Occupation_Scientist      29223 non-null  float64\n",
      " 41  Occupation_Teacher        29223 non-null  float64\n",
      " 42  Occupation_Writer         29223 non-null  float64\n",
      "dtypes: float64(24), int64(18), object(1)\n",
      "memory usage: 9.8+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Your code here:\n",
    "ohe = OneHotEncoder(sparse= False)\n",
    "df_fitted = ohe.fit_transform(df[['Occupation']])\n",
    "categories = ohe.get_feature_names_out(input_features=['Occupation'])\n",
    "df_encoded = pd.DataFrame(df_fitted, columns=categories, index= df.index)\n",
    "# Replace the 'Occupation' column with the one-hot encoded columns\n",
    "df_encoded = pd.concat([df.drop(['Occupation'], axis=1), df_encoded], axis=1)\n",
    "print(df_encoded.head())\n",
    "le = LabelEncoder()\n",
    "print(df['Payment_of_Min_Amount'], df['Payment_Behaviour'])\n",
    "df_encoded['Payment_of_Min_Amount'] = le.fit_transform(df_encoded['Payment_of_Min_Amount'])\n",
    "df_encoded['Payment_Behaviour'] = le.fit_transform(df_encoded['Payment_Behaviour'])\n",
    "\n",
    "print(df_encoded['Payment_of_Min_Amount'], df_encoded['Payment_Behaviour'])\n",
    "\n",
    "df_encoded.info()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfPnhUxAefVl"
   },
   "source": [
    "## 1.2 Dataset splitting\n",
    "\n",
    "Split the dataset in two, first X with your independent features and then y with the dependent feature **CreditMix**.\n",
    "\n",
    "Then perform :\n",
    "* OneHotEncoding over the **CreditMix** feature.\n",
    "* A MinMaxScaller over the independent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "J-mentarefVm",
    "outputId": "f955a93e-5e45-4f91-d183-0c3aa19e0caf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Credit_Mix_Bad  Credit_Mix_Good  Credit_Mix_Standard\n",
      "0                 0.0              1.0                  0.0\n",
      "1                 0.0              1.0                  0.0\n",
      "3                 0.0              1.0                  0.0\n",
      "5                 0.0              1.0                  0.0\n",
      "8                 0.0              1.0                  0.0\n",
      "...               ...              ...                  ...\n",
      "49990             0.0              1.0                  0.0\n",
      "49992             1.0              0.0                  0.0\n",
      "49993             1.0              0.0                  0.0\n",
      "49997             0.0              1.0                  0.0\n",
      "49998             0.0              1.0                  0.0\n",
      "\n",
      "[29223 rows x 3 columns]\n",
      "            Age  Annual_Income  Monthly_Inh_Salary  Num_Bank_Accounts  \\\n",
      "0      0.057177       0.000502            0.102087           0.002242   \n",
      "1      0.057287       0.000502            0.102087           0.002242   \n",
      "3      0.057287       0.000502            0.260275           0.002242   \n",
      "5      0.057724       0.001154            0.183501           0.001682   \n",
      "8      0.058489       0.005643            0.260275           0.001121   \n",
      "...         ...            ...                 ...                ...   \n",
      "49990  0.060129       0.001251            0.187462           0.001121   \n",
      "49992  0.057833       0.000539            0.109138           0.006166   \n",
      "49993  0.057833       0.000539            0.109138           0.006166   \n",
      "49997  0.057396       0.001352            0.205072           0.002803   \n",
      "49998  0.057396       0.001352            0.260275           0.002803   \n",
      "\n",
      "       Num_Credit_Card  Interest_Rate  Num_of_Loan  Delay_from_due_date  \\\n",
      "0             0.002668       0.000345     0.065163             0.111111   \n",
      "1             0.002668       0.000345     0.065163             0.111111   \n",
      "3             0.002668       0.000345     0.065163             0.125000   \n",
      "5             0.002668       0.000862     0.063283             0.111111   \n",
      "8             0.003336       0.001207     0.064536             0.180556   \n",
      "...                ...            ...          ...                  ...   \n",
      "49990         0.002668       0.733184     0.064536             0.166667   \n",
      "49992         0.005337       0.004829     0.065789             0.527778   \n",
      "49993         0.005337       0.004829     0.065789             0.527778   \n",
      "49997         0.004003       0.001035     0.063910             0.388889   \n",
      "49998         0.004003       0.001035     0.063910             0.361111   \n",
      "\n",
      "       Num_of_Delayed_Payment  Changed_Credit_Limit  ...  \\\n",
      "0                    0.002301              0.417727  ...   \n",
      "1                    0.002761              0.464875  ...   \n",
      "3                    0.001841              0.417727  ...   \n",
      "5                    0.001381              0.279821  ...   \n",
      "8                    0.447538              0.319425  ...   \n",
      "...                       ...                   ...  ...   \n",
      "49990                0.003451              0.278878  ...   \n",
      "49992                0.006443              0.583687  ...   \n",
      "49993                0.006443              0.583687  ...   \n",
      "49997                0.001841              0.470297  ...   \n",
      "49998                0.002071              0.423149  ...   \n",
      "\n",
      "       Occupation_Entrepreneur  Occupation_Journalist  Occupation_Lawyer  \\\n",
      "0                          0.0                    0.0                0.0   \n",
      "1                          0.0                    0.0                0.0   \n",
      "3                          0.0                    0.0                0.0   \n",
      "5                          0.0                    0.0                0.0   \n",
      "8                          0.0                    0.0                0.0   \n",
      "...                        ...                    ...                ...   \n",
      "49990                      0.0                    0.0                0.0   \n",
      "49992                      0.0                    0.0                0.0   \n",
      "49993                      0.0                    0.0                0.0   \n",
      "49997                      0.0                    0.0                0.0   \n",
      "49998                      0.0                    0.0                0.0   \n",
      "\n",
      "       Occupation_Manager  Occupation_Mechanic  Occupation_MediaManager  \\\n",
      "0                     0.0                  0.0                      0.0   \n",
      "1                     0.0                  0.0                      0.0   \n",
      "3                     0.0                  0.0                      0.0   \n",
      "5                     0.0                  0.0                      0.0   \n",
      "8                     0.0                  0.0                      0.0   \n",
      "...                   ...                  ...                      ...   \n",
      "49990                 0.0                  0.0                      0.0   \n",
      "49992                 0.0                  0.0                      0.0   \n",
      "49993                 0.0                  0.0                      0.0   \n",
      "49997                 0.0                  1.0                      0.0   \n",
      "49998                 0.0                  1.0                      0.0   \n",
      "\n",
      "       Occupation_Musician  Occupation_Scientist  Occupation_Teacher  \\\n",
      "0                      0.0                   1.0                 0.0   \n",
      "1                      0.0                   1.0                 0.0   \n",
      "3                      0.0                   1.0                 0.0   \n",
      "5                      0.0                   0.0                 1.0   \n",
      "8                      0.0                   0.0                 0.0   \n",
      "...                    ...                   ...                 ...   \n",
      "49990                  0.0                   0.0                 0.0   \n",
      "49992                  0.0                   0.0                 0.0   \n",
      "49993                  0.0                   0.0                 0.0   \n",
      "49997                  0.0                   0.0                 0.0   \n",
      "49998                  0.0                   0.0                 0.0   \n",
      "\n",
      "       Occupation_Writer  \n",
      "0                    0.0  \n",
      "1                    0.0  \n",
      "3                    0.0  \n",
      "5                    0.0  \n",
      "8                    0.0  \n",
      "...                  ...  \n",
      "49990                1.0  \n",
      "49992                0.0  \n",
      "49993                0.0  \n",
      "49997                0.0  \n",
      "49998                0.0  \n",
      "\n",
      "[29223 rows x 42 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "X = pd.DataFrame(df_encoded.drop(columns=['Credit_Mix']))\n",
    "y = pd.DataFrame(df_encoded['Credit_Mix'])\n",
    "#print(y.index)\n",
    "y_fitted = ohe.fit_transform(y[['Credit_Mix']])\n",
    "categories_credit_mix = ohe.get_feature_names_out(input_features=['Credit_Mix'])\n",
    "y = pd.DataFrame(y_fitted, columns=categories_credit_mix, index= y.index)\n",
    "# Replace the 'Occupation' column with the one-hot encoded columns\n",
    "#y = pd.concat([y.drop(['Credit_mix'], axis=1), y], axis=1)\n",
    "print(y)\n",
    "\n",
    "#Define the scaler\n",
    "scaler = MinMaxScaler()\n",
    "#Fit the scaler\n",
    "scaler.fit_transform(X)\n",
    "\n",
    "X.loc[:,:] = scaler.transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Train Test splitting\n",
    "Now split the data in X_train, X_test, y_train, y_test, \n",
    "\n",
    "You can use test_size = 0.2 and a random_state of 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yotEvoAxefVn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23378, 42) (5845, 42) (23378, 3) (5845, 3)\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 final touches\n",
    "Convert your datasets to `Torch tensors` of type `torch.float`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2KS_U8stefVo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23378, 42]) torch.Size([23378, 3]) torch.Size([5845, 3]) torch.Size([5845, 42])\n"
     ]
    }
   ],
   "source": [
    "#Your code here:\n",
    "X_train = torch.tensor(X_train.values, dtype=torch.float)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float)\n",
    "X_test = torch.tensor(X_test.values, dtype=torch.float)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float)\n",
    "print(X_train.size(), y_train.size(), y_test.size(), X_test.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Model preparation:\n",
    "\n",
    "## 2.1 Define a Neural network model and instantiate it.\n",
    "You can set the number of neurons to 150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8qqRoocVefVp"
   },
   "outputs": [],
   "source": [
    "# Define a neural network class here:\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H1, D_out):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(D_in, H1)        # Linear transformation for hidden layer\n",
    "        self.linear2 = nn.Linear(H1, D_out)       # Linear transformation for output layer\n",
    "        self.activation = nn.ReLU()               # Activation function for hidden layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.activation(self.linear1(x))   # Hidden layer: linear transformation + ReLU\n",
    "        y_pred = self.linear2(y_pred)               # Output layer: linear transformation\n",
    "        return y_pred\n",
    "\n",
    "# Define the input and output sizes\n",
    "D_in =  X_train.shape[1]\n",
    "D_out =  y_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cx-3yvp5efVp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (linear1): Linear(in_features=42, out_features=150, bias=True)\n",
      "  (linear2): Linear(in_features=150, out_features=3, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n",
      "6903\n"
     ]
    }
   ],
   "source": [
    "# Instantiate your model here\n",
    "model1 = Net(D_in, 150, D_out)\n",
    "print(model1)\n",
    "pytorch_total_params = sum(p.numel() for p in model1.parameters() if p.requires_grad)\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 finding the best model:\n",
    "Identify, amongst the following options the best parameters for your model:\n",
    "\n",
    "* `criterion` : [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html), [BCEWithLogitsLoss](hhttps://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html)\n",
    "* `iterations` : 150, 250, 500\n",
    "* `learning rate` : 0.00005, 0.001, 12.031\n",
    "\n",
    "\n",
    "_Hint: restart your runtime between each execution to ensure that previous neural networks dont interfere with your current one_\n",
    "\n",
    "_You can evaluate your model based on it's accuracy over the test set_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Xx9l8UOoefVq"
   },
   "outputs": [],
   "source": [
    "# Define your loss function here:\n",
    "criterion = torch.nn.BCEWithLogitsLoss()#reduction='sum')\n",
    "# Define your Adam optimizer for finding the weights of the network here\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z_pmZ0yAefVr",
    "outputId": "f065c474-ad2e-441b-b955-9e3193df2c87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6805695295333862\n",
      "1 0.676201343536377\n",
      "2 0.6719506978988647\n",
      "3 0.6678128838539124\n",
      "4 0.6637848019599915\n",
      "5 0.6598634719848633\n",
      "6 0.6560435891151428\n",
      "7 0.6523216962814331\n",
      "8 0.6486955881118774\n",
      "9 0.6451641321182251\n",
      "10 0.6417268514633179\n",
      "11 0.6383853554725647\n",
      "12 0.6351411938667297\n",
      "13 0.6319980025291443\n",
      "14 0.6289601922035217\n",
      "15 0.6260322332382202\n",
      "16 0.6232197880744934\n",
      "17 0.6205275058746338\n",
      "18 0.6179583668708801\n",
      "19 0.6155164241790771\n",
      "20 0.6132037043571472\n",
      "21 0.6110206246376038\n",
      "22 0.608964741230011\n",
      "23 0.6070305705070496\n",
      "24 0.6052109599113464\n",
      "25 0.6034952998161316\n",
      "26 0.6018697619438171\n",
      "27 0.6003177762031555\n",
      "28 0.5988200902938843\n",
      "29 0.5973576307296753\n",
      "30 0.5959108471870422\n",
      "31 0.5944617390632629\n",
      "32 0.5929926633834839\n",
      "33 0.5914890170097351\n",
      "34 0.5899384617805481\n",
      "35 0.5883327126502991\n",
      "36 0.5866656303405762\n",
      "37 0.5849342942237854\n",
      "38 0.5831383466720581\n",
      "39 0.5812796950340271\n",
      "40 0.5793615579605103\n",
      "41 0.5773864388465881\n",
      "42 0.5753595232963562\n",
      "43 0.5732859373092651\n",
      "44 0.5711706876754761\n",
      "45 0.5690184831619263\n",
      "46 0.5668315291404724\n",
      "47 0.564612865447998\n",
      "48 0.5623637437820435\n",
      "49 0.560084879398346\n",
      "50 0.5577764511108398\n",
      "51 0.5554386377334595\n",
      "52 0.5530710816383362\n",
      "53 0.5506720542907715\n",
      "54 0.5482398271560669\n",
      "55 0.5457746386528015\n",
      "56 0.5432758927345276\n",
      "57 0.5407434105873108\n",
      "58 0.5381779074668884\n",
      "59 0.5355802178382874\n",
      "60 0.5329517722129822\n",
      "61 0.5302940607070923\n",
      "62 0.5276097059249878\n",
      "63 0.5249009728431702\n",
      "64 0.5221706628799438\n",
      "65 0.5194215774536133\n",
      "66 0.5166558027267456\n",
      "67 0.5138776302337646\n",
      "68 0.5110891461372375\n",
      "69 0.5082924365997314\n",
      "70 0.5054904222488403\n",
      "71 0.5026852488517761\n",
      "72 0.49987947940826416\n",
      "73 0.497074693441391\n",
      "74 0.49427375197410583\n",
      "75 0.49147915840148926\n",
      "76 0.48869240283966064\n",
      "77 0.4859163463115692\n",
      "78 0.48315271735191345\n",
      "79 0.4804055988788605\n",
      "80 0.477678507566452\n",
      "81 0.474974125623703\n",
      "82 0.472295343875885\n",
      "83 0.46964576840400696\n",
      "84 0.46702733635902405\n",
      "85 0.4644419550895691\n",
      "86 0.46189209818840027\n",
      "87 0.45938044786453247\n",
      "88 0.45690682530403137\n",
      "89 0.4544726014137268\n",
      "90 0.4520782232284546\n",
      "91 0.449724406003952\n",
      "92 0.4474116563796997\n",
      "93 0.4451398253440857\n",
      "94 0.44290924072265625\n",
      "95 0.4407198429107666\n",
      "96 0.4385710656642914\n",
      "97 0.43646278977394104\n",
      "98 0.4343954026699066\n",
      "99 0.4323684871196747\n",
      "100 0.43038150668144226\n",
      "101 0.4284341633319855\n",
      "102 0.4265260696411133\n",
      "103 0.4246562421321869\n",
      "104 0.42282453179359436\n",
      "105 0.42103078961372375\n",
      "106 0.4192744493484497\n",
      "107 0.41755443811416626\n",
      "108 0.4158690273761749\n",
      "109 0.41421693563461304\n",
      "110 0.41259682178497314\n",
      "111 0.41100817918777466\n",
      "112 0.40944963693618774\n",
      "113 0.40792080760002136\n",
      "114 0.40642085671424866\n",
      "115 0.404949426651001\n",
      "116 0.40350526571273804\n",
      "117 0.4020874798297882\n",
      "118 0.40069523453712463\n",
      "119 0.3993275463581085\n",
      "120 0.39798322319984436\n",
      "121 0.3966614305973053\n",
      "122 0.3953617215156555\n",
      "123 0.3940836787223816\n",
      "124 0.3928259611129761\n",
      "125 0.3915878236293793\n",
      "126 0.3903685212135315\n",
      "127 0.3891679346561432\n",
      "128 0.38798531889915466\n",
      "129 0.3868204951286316\n",
      "130 0.38567250967025757\n",
      "131 0.3845408856868744\n",
      "132 0.38342511653900146\n",
      "133 0.3823246657848358\n",
      "134 0.38123899698257446\n",
      "135 0.38016772270202637\n",
      "136 0.3791103661060333\n",
      "137 0.3780667185783386\n",
      "138 0.3770363926887512\n",
      "139 0.37601903080940247\n",
      "140 0.37501421570777893\n",
      "141 0.37402141094207764\n",
      "142 0.37304016947746277\n",
      "143 0.3720705211162567\n",
      "144 0.37111222743988037\n",
      "145 0.37016499042510986\n",
      "146 0.36922818422317505\n",
      "147 0.3683018386363983\n",
      "148 0.3673858344554901\n",
      "149 0.3664798438549042\n",
      "150 0.36558324098587036\n",
      "151 0.36469605565071106\n",
      "152 0.36381796002388\n",
      "153 0.3629488945007324\n",
      "154 0.362088680267334\n",
      "155 0.3612368404865265\n",
      "156 0.36039337515830994\n",
      "157 0.35955801606178284\n",
      "158 0.3587309718132019\n",
      "159 0.3579118549823761\n",
      "160 0.3571005165576935\n",
      "161 0.3562967777252197\n",
      "162 0.35550013184547424\n",
      "163 0.3547101616859436\n",
      "164 0.35392680764198303\n",
      "165 0.35315003991127014\n",
      "166 0.3523789048194885\n",
      "167 0.35161319375038147\n",
      "168 0.35085293650627136\n",
      "169 0.3500972390174866\n",
      "170 0.3493466377258301\n",
      "171 0.34860116243362427\n",
      "172 0.3478606641292572\n",
      "173 0.3471256196498871\n",
      "174 0.34639546275138855\n",
      "175 0.34567245841026306\n",
      "176 0.344955712556839\n",
      "177 0.3442472517490387\n",
      "178 0.34354594349861145\n",
      "179 0.34285178780555725\n",
      "180 0.34216412901878357\n",
      "181 0.3414824604988098\n",
      "182 0.34080660343170166\n",
      "183 0.3401370048522949\n",
      "184 0.33947309851646423\n",
      "185 0.33881476521492004\n",
      "186 0.3381619453430176\n",
      "187 0.3375145494937897\n",
      "188 0.33687248826026917\n",
      "189 0.336235374212265\n",
      "190 0.3356032073497772\n",
      "191 0.3349757194519043\n",
      "192 0.3343530595302582\n",
      "193 0.33373507857322693\n",
      "194 0.33312147855758667\n",
      "195 0.33251258730888367\n",
      "196 0.3319082260131836\n",
      "197 0.331308513879776\n",
      "198 0.33071306347846985\n",
      "199 0.3301217555999756\n",
      "200 0.32953473925590515\n",
      "201 0.3289516568183899\n",
      "202 0.3283727169036865\n",
      "203 0.32779768109321594\n",
      "204 0.32722657918930054\n",
      "205 0.32665932178497314\n",
      "206 0.3260957598686218\n",
      "207 0.3255358636379242\n",
      "208 0.3249801695346832\n",
      "209 0.32442837953567505\n",
      "210 0.32388055324554443\n",
      "211 0.3233366906642914\n",
      "212 0.32279646396636963\n",
      "213 0.32225990295410156\n",
      "214 0.32172685861587524\n",
      "215 0.3211973309516907\n",
      "216 0.32067152857780457\n",
      "217 0.3201490640640259\n",
      "218 0.3196300268173218\n",
      "219 0.3191142976284027\n",
      "220 0.31860214471817017\n",
      "221 0.3180934190750122\n",
      "222 0.3175884783267975\n",
      "223 0.3170870840549469\n",
      "224 0.3165895342826843\n",
      "225 0.31609562039375305\n",
      "226 0.315605103969574\n",
      "227 0.3151182532310486\n",
      "228 0.3146350383758545\n",
      "229 0.3141554296016693\n",
      "230 0.31367939710617065\n",
      "231 0.31320658326148987\n",
      "232 0.31273725628852844\n",
      "233 0.3122715353965759\n",
      "234 0.3118094503879547\n",
      "235 0.3113507628440857\n",
      "236 0.3108958303928375\n",
      "237 0.31044459342956543\n",
      "238 0.30999675393104553\n",
      "239 0.30955246090888977\n",
      "240 0.30911150574684143\n",
      "241 0.3086736798286438\n",
      "242 0.30823883414268494\n",
      "243 0.3078070282936096\n",
      "244 0.3073783814907074\n",
      "245 0.30695274472236633\n",
      "246 0.30653029680252075\n",
      "247 0.30611082911491394\n",
      "248 0.3056944012641907\n",
      "249 0.3052808344364166\n",
      "250 0.3048703670501709\n",
      "251 0.30446308851242065\n",
      "252 0.30405890941619873\n",
      "253 0.30365774035453796\n",
      "254 0.3032594621181488\n",
      "255 0.30286410450935364\n",
      "256 0.30247166752815247\n",
      "257 0.3020819425582886\n",
      "258 0.3016948103904724\n",
      "259 0.30131036043167114\n",
      "260 0.30092859268188477\n",
      "261 0.3005494475364685\n",
      "262 0.30017271637916565\n",
      "263 0.29979851841926575\n",
      "264 0.2994268536567688\n",
      "265 0.2990576922893524\n",
      "266 0.29869115352630615\n",
      "267 0.2983272075653076\n",
      "268 0.2979656755924225\n",
      "269 0.29760658740997314\n",
      "270 0.2972498834133148\n",
      "271 0.2968956530094147\n",
      "272 0.2965437173843384\n",
      "273 0.2961939573287964\n",
      "274 0.2958466112613678\n",
      "275 0.2955012917518616\n",
      "276 0.29515790939331055\n",
      "277 0.2948167324066162\n",
      "278 0.29447758197784424\n",
      "279 0.29414069652557373\n",
      "280 0.293805867433548\n",
      "281 0.29347342252731323\n",
      "282 0.293143093585968\n",
      "283 0.29281479120254517\n",
      "284 0.29248854517936707\n",
      "285 0.29216429591178894\n",
      "286 0.29184219241142273\n",
      "287 0.2915220856666565\n",
      "288 0.29120394587516785\n",
      "289 0.2908877432346344\n",
      "290 0.29057344794273376\n",
      "291 0.2902608811855316\n",
      "292 0.28995025157928467\n",
      "293 0.2896415591239929\n",
      "294 0.2893347442150116\n",
      "295 0.2890297770500183\n",
      "296 0.2887267470359802\n",
      "297 0.28842586278915405\n",
      "298 0.2881268858909607\n",
      "299 0.2878296971321106\n",
      "300 0.28753435611724854\n",
      "301 0.2872408628463745\n",
      "302 0.2869492173194885\n",
      "303 0.2866593301296234\n",
      "304 0.2863713204860687\n",
      "305 0.2860850393772125\n",
      "306 0.28580039739608765\n",
      "307 0.2855173647403717\n",
      "308 0.28523585200309753\n",
      "309 0.284955769777298\n",
      "310 0.2846773564815521\n",
      "311 0.2844003736972809\n",
      "312 0.28412485122680664\n",
      "313 0.28385084867477417\n",
      "314 0.28357836604118347\n",
      "315 0.28330734372138977\n",
      "316 0.2830377221107483\n",
      "317 0.2827697694301605\n",
      "318 0.2825031578540802\n",
      "319 0.28223785758018494\n",
      "320 0.2819739580154419\n",
      "321 0.28171125054359436\n",
      "322 0.2814497947692871\n",
      "323 0.2811896800994873\n",
      "324 0.2809307873249054\n",
      "325 0.28067323565483093\n",
      "326 0.2804170250892639\n",
      "327 0.2801623046398163\n",
      "328 0.27990883588790894\n",
      "329 0.2796565592288971\n",
      "330 0.2794056534767151\n",
      "331 0.2791561782360077\n",
      "332 0.27890828251838684\n",
      "333 0.27866172790527344\n",
      "334 0.2784164845943451\n",
      "335 0.27817246317863464\n",
      "336 0.2779298424720764\n",
      "337 0.2776886224746704\n",
      "338 0.27744901180267334\n",
      "339 0.2772104740142822\n",
      "340 0.27697324752807617\n",
      "341 0.27673739194869995\n",
      "342 0.27650272846221924\n",
      "343 0.2762693166732788\n",
      "344 0.27603715658187866\n",
      "345 0.2758060693740845\n",
      "346 0.27557623386383057\n",
      "347 0.2753475308418274\n",
      "348 0.27511999011039734\n",
      "349 0.2748933732509613\n",
      "350 0.27466773986816406\n",
      "351 0.274443119764328\n",
      "352 0.2742196023464203\n",
      "353 0.27399691939353943\n",
      "354 0.2737753987312317\n",
      "355 0.27355483174324036\n",
      "356 0.27333536744117737\n",
      "357 0.2731170654296875\n",
      "358 0.272899866104126\n",
      "359 0.2726835310459137\n",
      "360 0.27246811985969543\n",
      "361 0.2722538411617279\n",
      "362 0.27204063534736633\n",
      "363 0.27182847261428833\n",
      "364 0.2716173827648163\n",
      "365 0.2714070975780487\n",
      "366 0.2711979150772095\n",
      "367 0.2709898054599762\n",
      "368 0.27078303694725037\n",
      "369 0.2705773413181305\n",
      "370 0.2703729569911957\n",
      "371 0.27016976475715637\n",
      "372 0.26996779441833496\n",
      "373 0.2697668671607971\n",
      "374 0.2695668637752533\n",
      "375 0.2693680226802826\n",
      "376 0.269170343875885\n",
      "377 0.2689736485481262\n",
      "378 0.268777996301651\n",
      "379 0.2685835063457489\n",
      "380 0.26839011907577515\n",
      "381 0.26819780468940735\n",
      "382 0.2680063843727112\n",
      "383 0.2678157687187195\n",
      "384 0.2676261365413666\n",
      "385 0.26743772625923157\n",
      "386 0.2672503590583801\n",
      "387 0.26706376671791077\n",
      "388 0.26687800884246826\n",
      "389 0.2666930854320526\n",
      "390 0.266509085893631\n",
      "391 0.26632604002952576\n",
      "392 0.2661438584327698\n",
      "393 0.2659623622894287\n",
      "394 0.26578155159950256\n",
      "395 0.2656014561653137\n",
      "396 0.26542213559150696\n",
      "397 0.2652434706687927\n",
      "398 0.26506534218788147\n",
      "399 0.2648877203464508\n",
      "400 0.2647106349468231\n",
      "401 0.26453426480293274\n",
      "402 0.26435860991477966\n",
      "403 0.2641838490962982\n",
      "404 0.26400962471961975\n",
      "405 0.2638360559940338\n",
      "406 0.26366308331489563\n",
      "407 0.26349079608917236\n",
      "408 0.2633192241191864\n",
      "409 0.2631482183933258\n",
      "410 0.2629777193069458\n",
      "411 0.262807697057724\n",
      "412 0.26263824105262756\n",
      "413 0.26246944069862366\n",
      "414 0.2623012065887451\n",
      "415 0.26213347911834717\n",
      "416 0.26196616888046265\n",
      "417 0.2617994546890259\n",
      "418 0.2616333067417145\n",
      "419 0.2614676356315613\n",
      "420 0.2613026201725006\n",
      "421 0.2611379027366638\n",
      "422 0.2609734833240509\n",
      "423 0.26080960035324097\n",
      "424 0.260646253824234\n",
      "425 0.2604834735393524\n",
      "426 0.26032131910324097\n",
      "427 0.2601596415042877\n",
      "428 0.25999847054481506\n",
      "429 0.2598377466201782\n",
      "430 0.2596776783466339\n",
      "431 0.259518027305603\n",
      "432 0.259358674287796\n",
      "433 0.2591997981071472\n",
      "434 0.25904151797294617\n",
      "435 0.25888365507125854\n",
      "436 0.25872620940208435\n",
      "437 0.25856930017471313\n",
      "438 0.2584131360054016\n",
      "439 0.2582573890686035\n",
      "440 0.258102148771286\n",
      "441 0.25794756412506104\n",
      "442 0.257793664932251\n",
      "443 0.2576403319835663\n",
      "444 0.2574876844882965\n",
      "445 0.25733551383018494\n",
      "446 0.25718390941619873\n",
      "447 0.2570328414440155\n",
      "448 0.2568824291229248\n",
      "449 0.25673240423202515\n",
      "450 0.2565825283527374\n",
      "451 0.2564332187175751\n",
      "452 0.25628456473350525\n",
      "453 0.2561361789703369\n",
      "454 0.2559882402420044\n",
      "455 0.25584080815315247\n",
      "456 0.2556939125061035\n",
      "457 0.2555476427078247\n",
      "458 0.25540149211883545\n",
      "459 0.25525572896003723\n",
      "460 0.2551107704639435\n",
      "461 0.2549666166305542\n",
      "462 0.2548227608203888\n",
      "463 0.25467953085899353\n",
      "464 0.2545364201068878\n",
      "465 0.2543937861919403\n",
      "466 0.25425201654434204\n",
      "467 0.2541106343269348\n",
      "468 0.2539694607257843\n",
      "469 0.25382810831069946\n",
      "470 0.2536877393722534\n",
      "471 0.25354817509651184\n",
      "472 0.2534084618091583\n",
      "473 0.2532694637775421\n",
      "474 0.25313112139701843\n",
      "475 0.25299325585365295\n",
      "476 0.2528557777404785\n",
      "477 0.2527179419994354\n",
      "478 0.2525809407234192\n",
      "479 0.25244471430778503\n",
      "480 0.2523089349269867\n",
      "481 0.2521737813949585\n",
      "482 0.2520391643047333\n",
      "483 0.2519053816795349\n",
      "484 0.25177204608917236\n",
      "485 0.25163906812667847\n",
      "486 0.25150641798973083\n",
      "487 0.2513739764690399\n",
      "488 0.25124236941337585\n",
      "489 0.2511114180088043\n",
      "490 0.25097915530204773\n",
      "491 0.25084859132766724\n",
      "492 0.25071921944618225\n",
      "493 0.25058895349502563\n",
      "494 0.2504597306251526\n",
      "495 0.2503317594528198\n",
      "496 0.25020256638526917\n",
      "497 0.25007539987564087\n",
      "498 0.24994820356369019\n",
      "499 0.2498197704553604\n"
     ]
    }
   ],
   "source": [
    "# Perform your iterations here\n",
    "losses1 = []\n",
    "losses1_test = []\n",
    "\n",
    "for t in range(500):                # 500 iterations\n",
    "\n",
    "    # Forward pass: compute prediction on training set\n",
    "    y_pred_train = model1(X_train)\n",
    "    y_pred_test = model1(X_test)\n",
    "    # Compute loss\n",
    "    loss = criterion(y_pred_train, y_train)\n",
    "    print(t, loss.item())\n",
    "    losses1.append(loss.item())\n",
    "    if torch.isnan(loss):\n",
    "        break\n",
    "\n",
    "    # Compute gradient\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Update\n",
    "    optimizer.step()\n",
    "\n",
    "    # Compute loss on test set\n",
    "    losses1_test.append(criterion(model1(X_test), y_test).item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Model Accuracy\n",
    "Identify the models accuracy over the train and test parts of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8339036701172042\n",
      "0.827715996578272\n"
     ]
    }
   ],
   "source": [
    "# deactivate dropout layers\n",
    "model1.eval()\n",
    "# Training accuracy\n",
    "\n",
    "# Convert y_train to a NumPy array if it's not already\n",
    "y_train = y_train.numpy() if isinstance(y_train, torch.Tensor) else y_train\n",
    "\n",
    "# Make sure both y_pred_train and y_train are 1D arrays of class labels\n",
    "y_pred_train = y_pred_train.argmax(axis=1) if len(y_pred_train.shape) > 1 else y_pred_train\n",
    "y_train = y_train.argmax(axis=1) if len(y_train.shape) > 1 else y_train\n",
    "\n",
    "# Check that the data types are integers\n",
    "#y_pred_train = y_pred_train.astype(int)\n",
    "y_train = y_train.astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "print(accuracy_train)\n",
    "\n",
    "# test accuracy\n",
    "y_test = y_test.numpy() if isinstance(y_test, torch.Tensor) else y_test\n",
    "\n",
    "# Make sure both y_pred_train and y_train are 1D arrays of class labels\n",
    "y_pred_test = y_pred_test.argmax(axis=1) if len(y_pred_test.shape) > 1 else y_pred_test\n",
    "y_test = y_test.argmax(axis=1) if len(y_test.shape) > 1 else y_test\n",
    "\n",
    "# Check that the data types are integers\n",
    "#y_pred_test = y_pred_test.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Predictions over the suspects dataset\n",
    "## 3.1 Retrain a new model over the full training dataset\n",
    "#### Please use the following parameters for this section:\n",
    "* ``neurons`` = 150\n",
    "* ``learning`` rate = 0.00005\n",
    "* ``criterion`` = CrossEntropyLoss\n",
    "* `iterations` = 500\n",
    "\n",
    "_hint you may have to redo some preprocessing as you did in part one_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 714 entries, 0 to 1237\n",
      "Data columns (total 42 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Age                       714 non-null    float64\n",
      " 1   Annual_Income             714 non-null    float64\n",
      " 2   Monthly_Inh_Salary        714 non-null    float64\n",
      " 3   Num_Bank_Accounts         714 non-null    float64\n",
      " 4   Num_Credit_Card           714 non-null    float64\n",
      " 5   Interest_Rate             714 non-null    float64\n",
      " 6   Num_of_Loan               714 non-null    float64\n",
      " 7   Delay_from_due_date       714 non-null    float64\n",
      " 8   Num_of_Delayed_Payment    714 non-null    float64\n",
      " 9   Changed_Credit_Limit      714 non-null    float64\n",
      " 10  Num_Credit_Inquiries      714 non-null    float64\n",
      " 11  Outsting_Debt             714 non-null    float64\n",
      " 12  Credit_Utilization_Ratio  714 non-null    float64\n",
      " 13  Payment_of_Min_Amount     714 non-null    int64  \n",
      " 14  Total_EMI_per_month       714 non-null    float64\n",
      " 15  Amount_invested_monthly   714 non-null    float64\n",
      " 16  Payment_Behaviour         714 non-null    int64  \n",
      " 17  Monthly_Balance           714 non-null    float64\n",
      " 18  AutoLoan                  714 non-null    float64\n",
      " 19  Credit-BuilderLoan        714 non-null    float64\n",
      " 20  DebtConsolidationLoan     714 non-null    float64\n",
      " 21  HomeEquityLoan            714 non-null    float64\n",
      " 22  MortgageLoan              714 non-null    float64\n",
      " 23  NotSpecified              714 non-null    float64\n",
      " 24  PaydayLoan                714 non-null    float64\n",
      " 25  PersonalLoan              714 non-null    float64\n",
      " 26  StudentLoan               714 non-null    float64\n",
      " 27  Occupation_Accountant     714 non-null    float64\n",
      " 28  Occupation_Architect      714 non-null    float64\n",
      " 29  Occupation_Developer      714 non-null    float64\n",
      " 30  Occupation_Doctor         714 non-null    float64\n",
      " 31  Occupation_Engineer       714 non-null    float64\n",
      " 32  Occupation_Entrepreneur   714 non-null    float64\n",
      " 33  Occupation_Journalist     714 non-null    float64\n",
      " 34  Occupation_Lawyer         714 non-null    float64\n",
      " 35  Occupation_Manager        714 non-null    float64\n",
      " 36  Occupation_Mechanic       714 non-null    float64\n",
      " 37  Occupation_MediaManager   714 non-null    float64\n",
      " 38  Occupation_Musician       714 non-null    float64\n",
      " 39  Occupation_Scientist      714 non-null    float64\n",
      " 40  Occupation_Teacher        714 non-null    float64\n",
      " 41  Occupation_Writer         714 non-null    float64\n",
      "dtypes: float64(40), int64(2)\n",
      "memory usage: 239.9 KB\n",
      "None\n",
      "torch.Size([29223, 42]) torch.Size([714, 42])\n"
     ]
    }
   ],
   "source": [
    "#preprocessing: X = training and suspects is testing dataset\n",
    "suspects = suspects.drop(columns=['userID'])\n",
    "print(suspects.info())\n",
    "X = torch.tensor(X.values, dtype=torch.float)\n",
    "suspects = torch.tensor(suspects.values, dtype=torch.float)\n",
    "print(X.size(), suspects.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H1, D_out):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(D_in, H1)        # Linear transformation for hidden layer\n",
    "        self.linear2 = nn.Linear(H1, D_out)       # Linear transformation for output layer\n",
    "        self.activation = nn.ReLU()               # Activation function for hidden layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.activation(self.linear1(x))   # Hidden layer: linear transformation + ReLU\n",
    "        y_pred = self.linear2(y_pred)               # Output layer: linear transformation\n",
    "        return y_pred\n",
    "\n",
    "# Define the input and output sizes\n",
    "D_in =  X.shape[1]\n",
    "D_out =  suspects.shape[1]\n",
    "\n",
    "model2 = Net(D_in, 150 , D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/.local/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# Define your MSE loss here:\n",
    "criterion = torch.nn.CrossEntropyLoss(reduce='mean')\n",
    "\n",
    "# Define your Adam optimizer for finding the weights of the network here:\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 625574.1875\n",
      "1 625574.1875\n",
      "2 625574.1875\n",
      "3 625574.1875\n",
      "4 625574.1875\n",
      "5 625574.1875\n",
      "6 625574.1875\n",
      "7 625574.1875\n",
      "8 625574.1875\n",
      "9 625574.1875\n",
      "10 625574.1875\n",
      "11 625574.1875\n",
      "12 625574.1875\n",
      "13 625574.1875\n",
      "14 625574.1875\n",
      "15 625574.1875\n",
      "16 625574.1875\n",
      "17 625574.1875\n",
      "18 625574.1875\n",
      "19 625574.1875\n",
      "20 625574.1875\n",
      "21 625574.1875\n",
      "22 625574.1875\n",
      "23 625574.1875\n",
      "24 625574.1875\n",
      "25 625574.1875\n",
      "26 625574.1875\n",
      "27 625574.1875\n",
      "28 625574.1875\n",
      "29 625574.1875\n",
      "30 625574.1875\n",
      "31 625574.1875\n",
      "32 625574.1875\n",
      "33 625574.1875\n",
      "34 625574.1875\n",
      "35 625574.1875\n",
      "36 625574.1875\n",
      "37 625574.1875\n",
      "38 625574.1875\n",
      "39 625574.1875\n",
      "40 625574.1875\n",
      "41 625574.1875\n",
      "42 625574.1875\n",
      "43 625574.1875\n",
      "44 625574.1875\n",
      "45 625574.1875\n",
      "46 625574.1875\n",
      "47 625574.1875\n",
      "48 625574.1875\n",
      "49 625574.1875\n",
      "50 625574.1875\n",
      "51 625574.1875\n",
      "52 625574.1875\n",
      "53 625574.1875\n",
      "54 625574.1875\n",
      "55 625574.1875\n",
      "56 625574.1875\n",
      "57 625574.1875\n",
      "58 625574.1875\n",
      "59 625574.1875\n",
      "60 625574.1875\n",
      "61 625574.1875\n",
      "62 625574.1875\n",
      "63 625574.1875\n",
      "64 625574.1875\n",
      "65 625574.1875\n",
      "66 625574.1875\n",
      "67 625574.1875\n",
      "68 625574.1875\n",
      "69 625574.1875\n",
      "70 625574.1875\n",
      "71 625574.1875\n",
      "72 625574.1875\n",
      "73 625574.1875\n",
      "74 625574.1875\n",
      "75 625574.1875\n",
      "76 625574.1875\n",
      "77 625574.1875\n",
      "78 625574.1875\n",
      "79 625574.1875\n",
      "80 625574.1875\n",
      "81 625574.1875\n",
      "82 625574.1875\n",
      "83 625574.1875\n",
      "84 625574.1875\n",
      "85 625574.1875\n",
      "86 625574.1875\n",
      "87 625574.1875\n",
      "88 625574.1875\n",
      "89 625574.1875\n",
      "90 625574.1875\n",
      "91 625574.1875\n",
      "92 625574.1875\n",
      "93 625574.1875\n",
      "94 625574.1875\n",
      "95 625574.1875\n",
      "96 625574.1875\n",
      "97 625574.1875\n",
      "98 625574.1875\n",
      "99 625574.1875\n",
      "100 625574.1875\n",
      "101 625574.1875\n",
      "102 625574.1875\n",
      "103 625574.1875\n",
      "104 625574.1875\n",
      "105 625574.1875\n",
      "106 625574.1875\n",
      "107 625574.1875\n",
      "108 625574.1875\n",
      "109 625574.1875\n",
      "110 625574.1875\n",
      "111 625574.1875\n",
      "112 625574.1875\n",
      "113 625574.1875\n",
      "114 625574.1875\n",
      "115 625574.1875\n",
      "116 625574.1875\n",
      "117 625574.1875\n",
      "118 625574.1875\n",
      "119 625574.1875\n",
      "120 625574.1875\n",
      "121 625574.1875\n",
      "122 625574.1875\n",
      "123 625574.1875\n",
      "124 625574.1875\n",
      "125 625574.1875\n",
      "126 625574.1875\n",
      "127 625574.1875\n",
      "128 625574.1875\n",
      "129 625574.1875\n",
      "130 625574.1875\n",
      "131 625574.1875\n",
      "132 625574.1875\n",
      "133 625574.1875\n",
      "134 625574.1875\n",
      "135 625574.1875\n",
      "136 625574.1875\n",
      "137 625574.1875\n",
      "138 625574.1875\n",
      "139 625574.1875\n",
      "140 625574.1875\n",
      "141 625574.1875\n",
      "142 625574.1875\n",
      "143 625574.1875\n",
      "144 625574.1875\n",
      "145 625574.1875\n",
      "146 625574.1875\n",
      "147 625574.1875\n",
      "148 625574.1875\n",
      "149 625574.1875\n",
      "150 625574.1875\n",
      "151 625574.1875\n",
      "152 625574.1875\n",
      "153 625574.1875\n",
      "154 625574.1875\n",
      "155 625574.1875\n",
      "156 625574.1875\n",
      "157 625574.1875\n",
      "158 625574.1875\n",
      "159 625574.1875\n",
      "160 625574.1875\n",
      "161 625574.1875\n",
      "162 625574.1875\n",
      "163 625574.1875\n",
      "164 625574.1875\n",
      "165 625574.1875\n",
      "166 625574.1875\n",
      "167 625574.1875\n",
      "168 625574.1875\n",
      "169 625574.1875\n",
      "170 625574.1875\n",
      "171 625574.1875\n",
      "172 625574.1875\n",
      "173 625574.1875\n",
      "174 625574.1875\n",
      "175 625574.1875\n",
      "176 625574.1875\n",
      "177 625574.1875\n",
      "178 625574.1875\n",
      "179 625574.1875\n",
      "180 625574.1875\n",
      "181 625574.1875\n",
      "182 625574.1875\n",
      "183 625574.1875\n",
      "184 625574.1875\n",
      "185 625574.1875\n",
      "186 625574.1875\n",
      "187 625574.1875\n",
      "188 625574.1875\n",
      "189 625574.1875\n",
      "190 625574.1875\n",
      "191 625574.1875\n",
      "192 625574.1875\n",
      "193 625574.1875\n",
      "194 625574.1875\n",
      "195 625574.1875\n",
      "196 625574.1875\n",
      "197 625574.1875\n",
      "198 625574.1875\n",
      "199 625574.1875\n",
      "200 625574.1875\n",
      "201 625574.1875\n",
      "202 625574.1875\n",
      "203 625574.1875\n",
      "204 625574.1875\n",
      "205 625574.1875\n",
      "206 625574.1875\n",
      "207 625574.1875\n",
      "208 625574.1875\n",
      "209 625574.1875\n",
      "210 625574.1875\n",
      "211 625574.1875\n",
      "212 625574.1875\n",
      "213 625574.1875\n",
      "214 625574.1875\n",
      "215 625574.1875\n",
      "216 625574.1875\n",
      "217 625574.1875\n",
      "218 625574.1875\n",
      "219 625574.1875\n",
      "220 625574.1875\n",
      "221 625574.1875\n",
      "222 625574.1875\n",
      "223 625574.1875\n",
      "224 625574.1875\n",
      "225 625574.1875\n",
      "226 625574.1875\n",
      "227 625574.1875\n",
      "228 625574.1875\n",
      "229 625574.1875\n",
      "230 625574.1875\n",
      "231 625574.1875\n",
      "232 625574.1875\n",
      "233 625574.1875\n",
      "234 625574.1875\n",
      "235 625574.1875\n",
      "236 625574.1875\n",
      "237 625574.1875\n",
      "238 625574.1875\n",
      "239 625574.1875\n",
      "240 625574.1875\n",
      "241 625574.1875\n",
      "242 625574.1875\n",
      "243 625574.1875\n",
      "244 625574.1875\n",
      "245 625574.1875\n",
      "246 625574.1875\n",
      "247 625574.1875\n",
      "248 625574.1875\n",
      "249 625574.1875\n",
      "250 625574.1875\n",
      "251 625574.1875\n",
      "252 625574.1875\n",
      "253 625574.1875\n",
      "254 625574.1875\n",
      "255 625574.1875\n",
      "256 625574.1875\n",
      "257 625574.1875\n",
      "258 625574.1875\n",
      "259 625574.1875\n",
      "260 625574.1875\n",
      "261 625574.1875\n",
      "262 625574.1875\n",
      "263 625574.1875\n",
      "264 625574.1875\n",
      "265 625574.1875\n",
      "266 625574.1875\n",
      "267 625574.1875\n",
      "268 625574.1875\n",
      "269 625574.1875\n",
      "270 625574.1875\n",
      "271 625574.1875\n",
      "272 625574.1875\n",
      "273 625574.1875\n",
      "274 625574.1875\n",
      "275 625574.1875\n",
      "276 625574.1875\n",
      "277 625574.1875\n",
      "278 625574.1875\n",
      "279 625574.1875\n",
      "280 625574.1875\n",
      "281 625574.1875\n",
      "282 625574.1875\n",
      "283 625574.1875\n",
      "284 625574.1875\n",
      "285 625574.1875\n",
      "286 625574.1875\n",
      "287 625574.1875\n",
      "288 625574.1875\n",
      "289 625574.1875\n",
      "290 625574.1875\n",
      "291 625574.1875\n",
      "292 625574.1875\n",
      "293 625574.1875\n",
      "294 625574.1875\n",
      "295 625574.1875\n",
      "296 625574.1875\n",
      "297 625574.1875\n",
      "298 625574.1875\n",
      "299 625574.1875\n",
      "300 625574.1875\n",
      "301 625574.1875\n",
      "302 625574.1875\n",
      "303 625574.1875\n",
      "304 625574.1875\n",
      "305 625574.1875\n",
      "306 625574.1875\n",
      "307 625574.1875\n",
      "308 625574.1875\n",
      "309 625574.1875\n",
      "310 625574.1875\n",
      "311 625574.1875\n",
      "312 625574.1875\n",
      "313 625574.1875\n",
      "314 625574.1875\n",
      "315 625574.1875\n",
      "316 625574.1875\n",
      "317 625574.1875\n",
      "318 625574.1875\n",
      "319 625574.1875\n",
      "320 625574.1875\n",
      "321 625574.1875\n",
      "322 625574.1875\n",
      "323 625574.1875\n",
      "324 625574.1875\n",
      "325 625574.1875\n",
      "326 625574.1875\n",
      "327 625574.1875\n",
      "328 625574.1875\n",
      "329 625574.1875\n",
      "330 625574.1875\n",
      "331 625574.1875\n",
      "332 625574.1875\n",
      "333 625574.1875\n",
      "334 625574.1875\n",
      "335 625574.1875\n",
      "336 625574.1875\n",
      "337 625574.1875\n",
      "338 625574.1875\n",
      "339 625574.1875\n",
      "340 625574.1875\n",
      "341 625574.1875\n",
      "342 625574.1875\n",
      "343 625574.1875\n",
      "344 625574.1875\n",
      "345 625574.1875\n",
      "346 625574.1875\n",
      "347 625574.1875\n",
      "348 625574.1875\n",
      "349 625574.1875\n",
      "350 625574.1875\n",
      "351 625574.1875\n",
      "352 625574.1875\n",
      "353 625574.1875\n",
      "354 625574.1875\n",
      "355 625574.1875\n",
      "356 625574.1875\n",
      "357 625574.1875\n",
      "358 625574.1875\n",
      "359 625574.1875\n",
      "360 625574.1875\n",
      "361 625574.1875\n",
      "362 625574.1875\n",
      "363 625574.1875\n",
      "364 625574.1875\n",
      "365 625574.1875\n",
      "366 625574.1875\n",
      "367 625574.1875\n",
      "368 625574.1875\n",
      "369 625574.1875\n",
      "370 625574.1875\n",
      "371 625574.1875\n",
      "372 625574.1875\n",
      "373 625574.1875\n",
      "374 625574.1875\n",
      "375 625574.1875\n",
      "376 625574.1875\n",
      "377 625574.1875\n",
      "378 625574.1875\n",
      "379 625574.1875\n",
      "380 625574.1875\n",
      "381 625574.1875\n",
      "382 625574.1875\n",
      "383 625574.1875\n",
      "384 625574.1875\n",
      "385 625574.1875\n",
      "386 625574.1875\n",
      "387 625574.1875\n",
      "388 625574.1875\n",
      "389 625574.1875\n",
      "390 625574.1875\n",
      "391 625574.1875\n",
      "392 625574.1875\n",
      "393 625574.1875\n",
      "394 625574.1875\n",
      "395 625574.1875\n",
      "396 625574.1875\n",
      "397 625574.1875\n",
      "398 625574.1875\n",
      "399 625574.1875\n",
      "400 625574.1875\n",
      "401 625574.1875\n",
      "402 625574.1875\n",
      "403 625574.1875\n",
      "404 625574.1875\n",
      "405 625574.1875\n",
      "406 625574.1875\n",
      "407 625574.1875\n",
      "408 625574.1875\n",
      "409 625574.1875\n",
      "410 625574.1875\n",
      "411 625574.1875\n",
      "412 625574.1875\n",
      "413 625574.1875\n",
      "414 625574.1875\n",
      "415 625574.1875\n",
      "416 625574.1875\n",
      "417 625574.1875\n",
      "418 625574.1875\n",
      "419 625574.1875\n",
      "420 625574.1875\n",
      "421 625574.1875\n",
      "422 625574.1875\n",
      "423 625574.1875\n",
      "424 625574.1875\n",
      "425 625574.1875\n",
      "426 625574.1875\n",
      "427 625574.1875\n",
      "428 625574.1875\n",
      "429 625574.1875\n",
      "430 625574.1875\n",
      "431 625574.1875\n",
      "432 625574.1875\n",
      "433 625574.1875\n",
      "434 625574.1875\n",
      "435 625574.1875\n",
      "436 625574.1875\n",
      "437 625574.1875\n",
      "438 625574.1875\n",
      "439 625574.1875\n",
      "440 625574.1875\n",
      "441 625574.1875\n",
      "442 625574.1875\n",
      "443 625574.1875\n",
      "444 625574.1875\n",
      "445 625574.1875\n",
      "446 625574.1875\n",
      "447 625574.1875\n",
      "448 625574.1875\n",
      "449 625574.1875\n",
      "450 625574.1875\n",
      "451 625574.1875\n",
      "452 625574.1875\n",
      "453 625574.1875\n",
      "454 625574.1875\n",
      "455 625574.1875\n",
      "456 625574.1875\n",
      "457 625574.1875\n",
      "458 625574.1875\n",
      "459 625574.1875\n",
      "460 625574.1875\n",
      "461 625574.1875\n",
      "462 625574.1875\n",
      "463 625574.1875\n",
      "464 625574.1875\n",
      "465 625574.1875\n",
      "466 625574.1875\n",
      "467 625574.1875\n",
      "468 625574.1875\n",
      "469 625574.1875\n",
      "470 625574.1875\n",
      "471 625574.1875\n",
      "472 625574.1875\n",
      "473 625574.1875\n",
      "474 625574.1875\n",
      "475 625574.1875\n",
      "476 625574.1875\n",
      "477 625574.1875\n",
      "478 625574.1875\n",
      "479 625574.1875\n",
      "480 625574.1875\n",
      "481 625574.1875\n",
      "482 625574.1875\n",
      "483 625574.1875\n",
      "484 625574.1875\n",
      "485 625574.1875\n",
      "486 625574.1875\n",
      "487 625574.1875\n",
      "488 625574.1875\n",
      "489 625574.1875\n",
      "490 625574.1875\n",
      "491 625574.1875\n",
      "492 625574.1875\n",
      "493 625574.1875\n",
      "494 625574.1875\n",
      "495 625574.1875\n",
      "496 625574.1875\n",
      "497 625574.1875\n",
      "498 625574.1875\n",
      "499 625574.1875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (linear1): Linear(in_features=42, out_features=150, bias=True)\n",
       "  (linear2): Linear(in_features=150, out_features=42, bias=True)\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform your training here\n",
    "losses1 = []\n",
    "losses1_test = []\n",
    "\n",
    "for t in range(500):                # 500 iterations\n",
    "\n",
    "    # Forward pass: compute prediction on training set\n",
    "    y_pred = model2(X)\n",
    "    batch_size = min(y_pred.size(0), suspects.size(0))\n",
    "    y_pred = y_pred[:batch_size]\n",
    "    suspects = suspects[:batch_size]\n",
    "\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(y_pred, suspects)\n",
    "    print(t, loss.item())\n",
    "    losses1.append(loss.item())\n",
    "    if torch.isnan(loss):\n",
    "        break\n",
    "\n",
    "    # Compute gradient\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Update\n",
    "    optimizer.step()\n",
    "\n",
    "model2.train()\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Predict over the suspects dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_vector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/nathan/OneDrive/GitHub/DataScience_and_MachineLearning/Assignements/Part 4/Assignment_part_four.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nathan/OneDrive/GitHub/DataScience_and_MachineLearning/Assignements/Part%204/Assignment_part_four.ipynb#X41sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     layer_2 \u001b[39m=\u001b[39m sigmoid(layer_1)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nathan/OneDrive/GitHub/DataScience_and_MachineLearning/Assignements/Part%204/Assignment_part_four.ipynb#X41sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_2\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/nathan/OneDrive/GitHub/DataScience_and_MachineLearning/Assignements/Part%204/Assignment_part_four.ipynb#X41sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m prediction \u001b[39m=\u001b[39m make_prediction(input_vector, weights_1, bias)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nathan/OneDrive/GitHub/DataScience_and_MachineLearning/Assignements/Part%204/Assignment_part_four.ipynb#X41sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe prediction result is: \u001b[39m\u001b[39m{\u001b[39;00mprediction\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_vector' is not defined"
     ]
    }
   ],
   "source": [
    "# Predict which users have a good credit score here:\n",
    "def sigmoid(x):\n",
    "   return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def make_prediction(input_vector, weights, bias):\n",
    "    layer_1 = np.dot(input_vector, weights) + bias\n",
    "    layer_2 = sigmoid(layer_1)\n",
    "    return layer_2\n",
    "\n",
    "prediction = make_prediction(input_vector, weights_1, bias)\n",
    "print(f\"The prediction result is: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
