{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/michalis0/DataScience_and_MachineLearning/blob/master/Assignements/Part%204/Assignment_part_four.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZu-7QbP9muh"
   },
   "source": [
    "DSML investigation:\n",
    "\n",
    "You are part of the Suisse Impossible Mission Force, or SIMF for short. You need to uncover a rogue agent that is trying to steal sensitive information.\n",
    "\n",
    "Your mission, should you choose to accept it, is to find that agent before stealing any classified information. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyL7WNdV9sWV"
   },
   "source": [
    "# Assignement part four\n",
    "### Due 22.10\n",
    "#### Identifying the suspects credit score\n",
    "We received informations that the rogue agent has a good credit score.\n",
    "\n",
    "Our spies at SIMF have managed to collect financial information relating to our suspects as well as a training dataset.\n",
    "\n",
    "Create a Neural Network over the training dataset `df` to identify which of the suspects have a good Credit_Mix\n",
    "\n",
    "\n",
    "## Getting to know our data\n",
    "\n",
    "* Age: a users age\n",
    "* Occupation: a users employment field\n",
    "* Annual_Income: a users annual income\n",
    "* Monthly_Inh_Salary: the calculated salary received by a given user on a monthly basis\n",
    "* Num_Bank_Accounts: the number of bank accounts possessed by a given user\n",
    "* Num_Credit_Cards: the number of credit card given user possesses\n",
    "* Interest_Rate: The interest rate on those cards (if multiple then its the average)\n",
    "* Num_of_Loans: The number of loans of each user\n",
    "* Delay_from_due_date: payment tardiness of user\n",
    "* Num_of_Delayed_Payment: the count of delayed payments\n",
    "* Changed_Credit_Limit: NaN\n",
    "* Num_Credit_Inquiries: NaN\n",
    "* Credit_Mix: The users credit score\n",
    "* Outsting_Debt: Outstanding debt\n",
    "* Credit_Utilization_Ratio: the percentage of borrowed money over borrowing allowance\n",
    "* Payment_of_Min_Amount: does the user usually pay the minimal amount (categorical)\n",
    "* Total_EMI_per_month: Monthly repayments to be made\n",
    "* Amount_invested_monthly: The amout put in an investment fun by the user on a monthly basis\n",
    "* Payment_Behaviour: the users payment behavior (categorical)\n",
    "* Monthly_Balance: The users end of the month balance\n",
    "* AutoLoan: If the user has an active loan for their vehicule\n",
    "* Credit-BuilderLoan: If the user has a loan to increase their credit score\n",
    "* DebtConsolidationLoan, HomeEquityLoan, MortgageLoan, NotSpecified, PaydayLoan, PersonalLoan, StudentLoan: different types of loans(categorical features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XHhI95r5-tyD"
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/michalis0/DataScience_and_MachineLearning/master/Assignements/Part%204/data/train_classification.csv\", index_col='Unnamed: 0').dropna()\n",
    "suspects = pd.read_csv(\"https://raw.githubusercontent.com/michalis0/DataScience_and_MachineLearning/master/Assignements/Part%204/data/suspects.csv\", index_col='Unnamed: 0').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 29223 entries, 0 to 49998\n",
      "Data columns (total 29 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Age                       29223 non-null  int64  \n",
      " 1   Occupation                29223 non-null  object \n",
      " 2   Annual_Income             29223 non-null  float64\n",
      " 3   Monthly_Inh_Salary        29223 non-null  float64\n",
      " 4   Num_Bank_Accounts         29223 non-null  int64  \n",
      " 5   Num_Credit_Card           29223 non-null  int64  \n",
      " 6   Interest_Rate             29223 non-null  int64  \n",
      " 7   Num_of_Loan               29223 non-null  int64  \n",
      " 8   Delay_from_due_date       29223 non-null  int64  \n",
      " 9   Num_of_Delayed_Payment    29223 non-null  int64  \n",
      " 10  Changed_Credit_Limit      29223 non-null  float64\n",
      " 11  Num_Credit_Inquiries      29223 non-null  float64\n",
      " 12  Credit_Mix                29223 non-null  object \n",
      " 13  Outsting_Debt             29223 non-null  float64\n",
      " 14  Credit_Utilization_Ratio  29223 non-null  float64\n",
      " 15  Payment_of_Min_Amount     29223 non-null  object \n",
      " 16  Total_EMI_per_month       29223 non-null  float64\n",
      " 17  Amount_invested_monthly   29223 non-null  float64\n",
      " 18  Payment_Behaviour         29223 non-null  object \n",
      " 19  Monthly_Balance           29223 non-null  float64\n",
      " 20  AutoLoan                  29223 non-null  int64  \n",
      " 21  Credit-BuilderLoan        29223 non-null  int64  \n",
      " 22  DebtConsolidationLoan     29223 non-null  int64  \n",
      " 23  HomeEquityLoan            29223 non-null  int64  \n",
      " 24  MortgageLoan              29223 non-null  int64  \n",
      " 25  NotSpecified              29223 non-null  int64  \n",
      " 26  PaydayLoan                29223 non-null  int64  \n",
      " 27  PersonalLoan              29223 non-null  int64  \n",
      " 28  StudentLoan               29223 non-null  int64  \n",
      "dtypes: float64(9), int64(16), object(4)\n",
      "memory usage: 6.7+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 714 entries, 0 to 1237\n",
      "Data columns (total 43 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Age                       714 non-null    float64\n",
      " 1   Annual_Income             714 non-null    float64\n",
      " 2   Monthly_Inh_Salary        714 non-null    float64\n",
      " 3   Num_Bank_Accounts         714 non-null    float64\n",
      " 4   Num_Credit_Card           714 non-null    float64\n",
      " 5   Interest_Rate             714 non-null    float64\n",
      " 6   Num_of_Loan               714 non-null    float64\n",
      " 7   Delay_from_due_date       714 non-null    float64\n",
      " 8   Num_of_Delayed_Payment    714 non-null    float64\n",
      " 9   Changed_Credit_Limit      714 non-null    float64\n",
      " 10  Num_Credit_Inquiries      714 non-null    float64\n",
      " 11  Outsting_Debt             714 non-null    float64\n",
      " 12  Credit_Utilization_Ratio  714 non-null    float64\n",
      " 13  Payment_of_Min_Amount     714 non-null    int64  \n",
      " 14  Total_EMI_per_month       714 non-null    float64\n",
      " 15  Amount_invested_monthly   714 non-null    float64\n",
      " 16  Payment_Behaviour         714 non-null    int64  \n",
      " 17  Monthly_Balance           714 non-null    float64\n",
      " 18  AutoLoan                  714 non-null    float64\n",
      " 19  Credit-BuilderLoan        714 non-null    float64\n",
      " 20  DebtConsolidationLoan     714 non-null    float64\n",
      " 21  HomeEquityLoan            714 non-null    float64\n",
      " 22  MortgageLoan              714 non-null    float64\n",
      " 23  NotSpecified              714 non-null    float64\n",
      " 24  PaydayLoan                714 non-null    float64\n",
      " 25  PersonalLoan              714 non-null    float64\n",
      " 26  StudentLoan               714 non-null    float64\n",
      " 27  Occupation_Accountant     714 non-null    float64\n",
      " 28  Occupation_Architect      714 non-null    float64\n",
      " 29  Occupation_Developer      714 non-null    float64\n",
      " 30  Occupation_Doctor         714 non-null    float64\n",
      " 31  Occupation_Engineer       714 non-null    float64\n",
      " 32  Occupation_Entrepreneur   714 non-null    float64\n",
      " 33  Occupation_Journalist     714 non-null    float64\n",
      " 34  Occupation_Lawyer         714 non-null    float64\n",
      " 35  Occupation_Manager        714 non-null    float64\n",
      " 36  Occupation_Mechanic       714 non-null    float64\n",
      " 37  Occupation_MediaManager   714 non-null    float64\n",
      " 38  Occupation_Musician       714 non-null    float64\n",
      " 39  Occupation_Scientist      714 non-null    float64\n",
      " 40  Occupation_Teacher        714 non-null    float64\n",
      " 41  Occupation_Writer         714 non-null    float64\n",
      " 42  userID                    714 non-null    int64  \n",
      "dtypes: float64(40), int64(3)\n",
      "memory usage: 245.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "suspects.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Credit_Mix\n",
       "Standard    13421\n",
       "Good         8963\n",
       "Bad          6839\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Credit_Mix\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZENObtyefVk"
   },
   "source": [
    "# 1. Preparing the data\n",
    "## 1.1 Data cleaning\n",
    " Perform OHE over the \"Occupation\" feature\n",
    "\n",
    " Then, perform LE over Payment_of_Min_Amount and Payment_Behaviour\n",
    "\n",
    " _hint: As we will be testing only one model no need to define a pipeline_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JGVrLNJTefVk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Age  Annual_Income  Monthly_Inh_Salary  Num_Bank_Accounts  \\\n",
      "0       23       19114.12         1824.843333                  3   \n",
      "1       24       19114.12         1824.843333                  3   \n",
      "3       24       19114.12         4182.004291                  3   \n",
      "5       28       34847.84         3037.986667                  2   \n",
      "8       35      143162.64         4182.004291                  1   \n",
      "...    ...            ...                 ...                ...   \n",
      "49990   50       37188.10         3097.008333                  1   \n",
      "49992   29       20002.88         1929.906667                 10   \n",
      "49993   29       20002.88         1929.906667                 10   \n",
      "49997   25       39628.99         3359.415833                  4   \n",
      "49998   25       39628.99         4182.004291                  4   \n",
      "\n",
      "       Num_Credit_Card  Interest_Rate  Num_of_Loan  Delay_from_due_date  \\\n",
      "0                    4              3            4                    3   \n",
      "1                    4              3            4                    3   \n",
      "3                    4              3            4                    4   \n",
      "5                    4              6            1                    3   \n",
      "8                    5              8            3                    8   \n",
      "...                ...            ...          ...                  ...   \n",
      "49990                4           4252            3                    7   \n",
      "49992                8             29            5                   33   \n",
      "49993                8             29            5                   33   \n",
      "49997                6              7            2                   23   \n",
      "49998                6              7            2                   21   \n",
      "\n",
      "       Num_of_Delayed_Payment  Changed_Credit_Limit  ...  \\\n",
      "0                           7                 11.27  ...   \n",
      "1                           9                 13.27  ...   \n",
      "3                           5                 11.27  ...   \n",
      "5                           3                  5.42  ...   \n",
      "8                        1942                  7.10  ...   \n",
      "...                       ...                   ...  ...   \n",
      "49990                      12                  5.38  ...   \n",
      "49992                      25                 18.31  ...   \n",
      "49993                      25                 18.31  ...   \n",
      "49997                       5                 13.50  ...   \n",
      "49998                       6                 11.50  ...   \n",
      "\n",
      "       Occupation_Entrepreneur Occupation_Journalist  Occupation_Lawyer  \\\n",
      "0                          0.0                   0.0                0.0   \n",
      "1                          0.0                   0.0                0.0   \n",
      "3                          0.0                   0.0                0.0   \n",
      "5                          0.0                   0.0                0.0   \n",
      "8                          0.0                   0.0                0.0   \n",
      "...                        ...                   ...                ...   \n",
      "49990                      0.0                   0.0                0.0   \n",
      "49992                      0.0                   0.0                0.0   \n",
      "49993                      0.0                   0.0                0.0   \n",
      "49997                      0.0                   0.0                0.0   \n",
      "49998                      0.0                   0.0                0.0   \n",
      "\n",
      "       Occupation_Manager  Occupation_Mechanic  Occupation_MediaManager  \\\n",
      "0                     0.0                  0.0                      0.0   \n",
      "1                     0.0                  0.0                      0.0   \n",
      "3                     0.0                  0.0                      0.0   \n",
      "5                     0.0                  0.0                      0.0   \n",
      "8                     0.0                  0.0                      0.0   \n",
      "...                   ...                  ...                      ...   \n",
      "49990                 0.0                  0.0                      0.0   \n",
      "49992                 0.0                  0.0                      0.0   \n",
      "49993                 0.0                  0.0                      0.0   \n",
      "49997                 0.0                  1.0                      0.0   \n",
      "49998                 0.0                  1.0                      0.0   \n",
      "\n",
      "       Occupation_Musician  Occupation_Scientist  Occupation_Teacher  \\\n",
      "0                      0.0                   1.0                 0.0   \n",
      "1                      0.0                   1.0                 0.0   \n",
      "3                      0.0                   1.0                 0.0   \n",
      "5                      0.0                   0.0                 1.0   \n",
      "8                      0.0                   0.0                 0.0   \n",
      "...                    ...                   ...                 ...   \n",
      "49990                  0.0                   0.0                 0.0   \n",
      "49992                  0.0                   0.0                 0.0   \n",
      "49993                  0.0                   0.0                 0.0   \n",
      "49997                  0.0                   0.0                 0.0   \n",
      "49998                  0.0                   0.0                 0.0   \n",
      "\n",
      "       Occupation_Writer  \n",
      "0                    0.0  \n",
      "1                    0.0  \n",
      "3                    0.0  \n",
      "5                    0.0  \n",
      "8                    0.0  \n",
      "...                  ...  \n",
      "49990                1.0  \n",
      "49992                0.0  \n",
      "49993                0.0  \n",
      "49997                0.0  \n",
      "49998                0.0  \n",
      "\n",
      "[29223 rows x 43 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Your code here:\n",
    "ohe = OneHotEncoder(sparse= False)\n",
    "df_fitted = ohe.fit_transform(df[['Occupation']])\n",
    "categories = ohe.get_feature_names_out(input_features=['Occupation'])\n",
    "df_encoded = pd.DataFrame(df_fitted, columns=categories, index= df.index)\n",
    "# Replace the 'Occupation' column with the one-hot encoded columns\n",
    "df_encoded = pd.concat([df.drop(['Occupation'], axis=1), df_encoded], axis=1)\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_encoded['Payment_of_Min_Amount'] = le.fit_transform(df_encoded['Payment_of_Min_Amount'])\n",
    "df_encoded['Payment_Behaviour'] = le.fit_transform(df_encoded['Payment_Behaviour'])\n",
    "\n",
    "print(df_encoded)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfPnhUxAefVl"
   },
   "source": [
    "## 1.2 Dataset splitting\n",
    "\n",
    "Split the dataset in two, first X with your independent features and then y with the dependent feature **CreditMix**.\n",
    "\n",
    "Then perform :\n",
    "* OneHotEncoding over the **CreditMix** feature.\n",
    "* A MinMaxScaller over the independent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "J-mentarefVm",
    "outputId": "f955a93e-5e45-4f91-d183-0c3aa19e0caf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Credit_Mix_Bad  Credit_Mix_Good  Credit_Mix_Standard\n",
      "0                 0.0              1.0                  0.0\n",
      "1                 0.0              1.0                  0.0\n",
      "3                 0.0              1.0                  0.0\n",
      "5                 0.0              1.0                  0.0\n",
      "8                 0.0              1.0                  0.0\n",
      "...               ...              ...                  ...\n",
      "49990             0.0              1.0                  0.0\n",
      "49992             1.0              0.0                  0.0\n",
      "49993             1.0              0.0                  0.0\n",
      "49997             0.0              1.0                  0.0\n",
      "49998             0.0              1.0                  0.0\n",
      "\n",
      "[29223 rows x 3 columns]\n",
      "[[5.71772166e-02 5.01784709e-04 1.02087051e-01 ... 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.72865420e-02 5.01784709e-04 1.02087051e-01 ... 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.72865420e-02 5.01784709e-04 2.60275285e-01 ... 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [5.78331693e-02 5.38616488e-04 1.09137814e-01 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.73958675e-02 1.35195704e-03 2.05071666e-01 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.73958675e-02 1.35195704e-03 2.60275285e-01 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "X = pd.DataFrame(df_encoded.drop(columns=['Credit_Mix']))\n",
    "y = pd.DataFrame(df_encoded['Credit_Mix'])\n",
    "#print(y.index)\n",
    "y_fitted = ohe.fit_transform(y[['Credit_Mix']])\n",
    "categories_credit_mix = ohe.get_feature_names_out(input_features=['Credit_Mix'])\n",
    "y = pd.DataFrame(y_fitted, columns=categories_credit_mix, index= y.index)\n",
    "# Replace the 'Occupation' column with the one-hot encoded columns\n",
    "#y = pd.concat([y.drop(['Credit_mix'], axis=1), y], axis=1)\n",
    "print(y)\n",
    "\n",
    "#Define the scaler\n",
    "scaler = MinMaxScaler()\n",
    "#Fit the scaler\n",
    "X = scaler.fit_transform(X)\n",
    "#X = pd.DataFrame(X, columns=)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Train Test splitting\n",
    "Now split the data in X_train, X_test, y_train, y_test, \n",
    "\n",
    "You can use test_size = 0.2 and a random_state of 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yotEvoAxefVn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23378, 42) (5845, 42) (23378, 3) (5845, 3)\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 final touches\n",
    "Convert your datasets to `Torch tensors` of type `torch.float`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2KS_U8stefVo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23378, 42]) torch.Size([23378, 3]) torch.Size([5845, 3]) torch.Size([5845, 42])\n"
     ]
    }
   ],
   "source": [
    "#Your code here:\n",
    "X_train = torch.tensor(X_train.values, dtype=torch.float)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float)\n",
    "X_test = torch.tensor(X_test.values, dtype=torch.float)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float)\n",
    "print(X_train.size(), y_train.size(), y_test.size(), X_test.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Model preparation:\n",
    "\n",
    "## 2.1 Define a Neural network model and instantiate it.\n",
    "You can set the number of neurons to 150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8qqRoocVefVp"
   },
   "outputs": [],
   "source": [
    "# Define a neural network class here:\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H1, D_out):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(D_in, H1)        # Linear transformation for hidden layer\n",
    "        self.linear2 = nn.Linear(H1, D_out)       # Linear transformation for output layer\n",
    "        self.activation = nn.ReLU()               # Activation function for hidden layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.activation(self.linear1(x))   # Hidden layer: linear transformation + ReLU\n",
    "        y_pred = self.linear2(y_pred)               # Output layer: linear transformation\n",
    "        return y_pred\n",
    "\n",
    "# Define the input and output sizes\n",
    "D_in =  X_train.shape[1]\n",
    "D_out =  y_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cx-3yvp5efVp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (linear1): Linear(in_features=42, out_features=150, bias=True)\n",
      "  (linear2): Linear(in_features=150, out_features=3, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n",
      "6903\n"
     ]
    }
   ],
   "source": [
    "# Instantiate your model here\n",
    "model1 = Net(D_in, 150, D_out)\n",
    "print(model1)\n",
    "pytorch_total_params = sum(p.numel() for p in model1.parameters() if p.requires_grad)\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 finding the best model:\n",
    "Identify, amongst the following options the best parameters for your model:\n",
    "\n",
    "* `criterion` : [CrossEntropyLoss](https://anvilproject.org/guides/content/creating-links), [BCEWithLogitsLoss](hhttps://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html)\n",
    "* `iterations` : 150, 250, 500\n",
    "* `learning rate` : 0.00005, 0.001, 12.031\n",
    "\n",
    "\n",
    "_Hint: restart your runtime between each execution to ensure that previous neural networks dont interfere with your current one_\n",
    "\n",
    "_You can evaluate your model based on it's accuracy over the test set_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Xx9l8UOoefVq"
   },
   "outputs": [],
   "source": [
    "# Define your loss function here:\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Define your SGD optimizer for finding the weights of the network here\n",
    "optimizer = torch.optim.SGD(model1.parameters(), lr=0.000005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z_pmZ0yAefVr",
    "outputId": "f065c474-ad2e-441b-b955-9e3193df2c87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.1057748794555664\n",
      "1 1.1057744026184082\n",
      "2 1.1057738065719604\n",
      "3 1.1057732105255127\n",
      "4 1.1057727336883545\n",
      "5 1.1057721376419067\n",
      "6 1.105771541595459\n",
      "7 1.1057710647583008\n",
      "8 1.105770468711853\n",
      "9 1.1057699918746948\n",
      "10 1.105769395828247\n",
      "11 1.1057686805725098\n",
      "12 1.1057682037353516\n",
      "13 1.1057674884796143\n",
      "14 1.105767011642456\n",
      "15 1.1057665348052979\n",
      "16 1.1057660579681396\n",
      "17 1.1057653427124023\n",
      "18 1.1057648658752441\n",
      "19 1.1057642698287964\n",
      "20 1.1057636737823486\n",
      "21 1.1057631969451904\n",
      "22 1.1057626008987427\n",
      "23 1.105762004852295\n",
      "24 1.1057615280151367\n",
      "25 1.1057608127593994\n",
      "26 1.1057603359222412\n",
      "27 1.1057597398757935\n",
      "28 1.1057592630386353\n",
      "29 1.1057586669921875\n",
      "30 1.1057580709457397\n",
      "31 1.105757474899292\n",
      "32 1.1057569980621338\n",
      "33 1.1057565212249756\n",
      "34 1.1057558059692383\n",
      "35 1.1057552099227905\n",
      "36 1.1057547330856323\n",
      "37 1.1057541370391846\n",
      "38 1.1057536602020264\n",
      "39 1.105752944946289\n",
      "40 1.1057524681091309\n",
      "41 1.1057519912719727\n",
      "42 1.1057512760162354\n",
      "43 1.1057507991790771\n",
      "44 1.1057502031326294\n",
      "45 1.1057497262954712\n",
      "46 1.1057491302490234\n",
      "47 1.1057486534118652\n",
      "48 1.105747938156128\n",
      "49 1.1057474613189697\n",
      "50 1.1057469844818115\n",
      "51 1.1057462692260742\n",
      "52 1.1057456731796265\n",
      "53 1.1057451963424683\n",
      "54 1.10574471950531\n",
      "55 1.1057440042495728\n",
      "56 1.1057435274124146\n",
      "57 1.1057429313659668\n",
      "58 1.105742335319519\n",
      "59 1.1057418584823608\n",
      "60 1.105741262435913\n",
      "61 1.1057406663894653\n",
      "62 1.1057400703430176\n",
      "63 1.1057395935058594\n",
      "64 1.1057389974594116\n",
      "65 1.1057384014129639\n",
      "66 1.1057379245758057\n",
      "67 1.1057374477386475\n",
      "68 1.1057367324829102\n",
      "69 1.1057361364364624\n",
      "70 1.1057356595993042\n",
      "71 1.1057350635528564\n",
      "72 1.1057344675064087\n",
      "73 1.105733871459961\n",
      "74 1.1057333946228027\n",
      "75 1.105732798576355\n",
      "76 1.1057322025299072\n",
      "77 1.105731725692749\n",
      "78 1.1057311296463013\n",
      "79 1.105730652809143\n",
      "80 1.1057300567626953\n",
      "81 1.1057294607162476\n",
      "82 1.1057288646697998\n",
      "83 1.1057283878326416\n",
      "84 1.1057277917861938\n",
      "85 1.105727195739746\n",
      "86 1.1057265996932983\n",
      "87 1.1057261228561401\n",
      "88 1.1057255268096924\n",
      "89 1.1057249307632446\n",
      "90 1.1057244539260864\n",
      "91 1.1057238578796387\n",
      "92 1.105723261833191\n",
      "93 1.1057226657867432\n",
      "94 1.105722188949585\n",
      "95 1.1057215929031372\n",
      "96 1.105721116065979\n",
      "97 1.1057205200195312\n",
      "98 1.1057199239730835\n",
      "99 1.1057193279266357\n",
      "100 1.1057188510894775\n",
      "101 1.1057182550430298\n",
      "102 1.105717658996582\n",
      "103 1.1057171821594238\n",
      "104 1.105716586112976\n",
      "105 1.1057158708572388\n",
      "106 1.1057155132293701\n",
      "107 1.1057149171829224\n",
      "108 1.1057143211364746\n",
      "109 1.1057138442993164\n",
      "110 1.105713129043579\n",
      "111 1.1057125329971313\n",
      "112 1.1057120561599731\n",
      "113 1.105711579322815\n",
      "114 1.1057109832763672\n",
      "115 1.1057103872299194\n",
      "116 1.1057099103927612\n",
      "117 1.105709195137024\n",
      "118 1.1057085990905762\n",
      "119 1.105708122253418\n",
      "120 1.1057075262069702\n",
      "121 1.105707049369812\n",
      "122 1.1057064533233643\n",
      "123 1.1057058572769165\n",
      "124 1.1057053804397583\n",
      "125 1.105704665184021\n",
      "126 1.1057041883468628\n",
      "127 1.105703592300415\n",
      "128 1.1057029962539673\n",
      "129 1.105702519416809\n",
      "130 1.1057019233703613\n",
      "131 1.1057014465332031\n",
      "132 1.1057008504867554\n",
      "133 1.1057003736495972\n",
      "134 1.1056996583938599\n",
      "135 1.1056989431381226\n",
      "136 1.105698585510254\n",
      "137 1.1056979894638062\n",
      "138 1.105697512626648\n",
      "139 1.1056969165802002\n",
      "140 1.1056963205337524\n",
      "141 1.1056958436965942\n",
      "142 1.1056952476501465\n",
      "143 1.1056947708129883\n",
      "144 1.1056939363479614\n",
      "145 1.1056934595108032\n",
      "146 1.105692982673645\n",
      "147 1.1056925058364868\n",
      "148 1.1056917905807495\n",
      "149 1.1056913137435913\n"
     ]
    }
   ],
   "source": [
    "# Perform your iterations here\n",
    "losses1 = []\n",
    "losses1_test = []\n",
    "\n",
    "for t in range(150):                # 500 iterations\n",
    "\n",
    "    # Forward pass: compute prediction on training set\n",
    "    y_pred = model1(X_train)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    print(t, loss.item())\n",
    "    losses1.append(loss.item())\n",
    "    if torch.isnan(loss):\n",
    "        break\n",
    "\n",
    "    # Compute gradient\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Update\n",
    "    optimizer.step()\n",
    "\n",
    "    # Compute loss on test set\n",
    "    losses1_test.append(criterion(model1(X_test), y_test).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Model Accuracy\n",
    "Identify the models accuracy over the train and test parts of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deactivate dropout layers\n",
    "\n",
    "# Training accuracy\n",
    "\n",
    "\n",
    "# Test accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Predictions over the suspects dataset\n",
    "## 3.1 Retrain a new model over the full training dataset\n",
    "#### Please use the following parameters for this section:\n",
    "* ``neurons`` = 150\n",
    "* ``learning`` rate = 0.00005\n",
    "* ``criterion`` = CrossEntropyLoss\n",
    "* `iterations` = 500\n",
    "\n",
    "_hint you may have to redo some preprocessing as you did in part one_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([29223, 42]) torch.Size([29223, 42]) torch.Size([714, 42]) tensor([[2.3000e+01, 1.9114e+04, 1.8248e+03,  ..., 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [2.4000e+01, 1.9114e+04, 1.8248e+03,  ..., 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [2.4000e+01, 1.9114e+04, 4.1820e+03,  ..., 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [3.4000e+01, 1.5736e+04, 1.0433e+03,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [3.2000e+01, 2.0503e+04, 4.1820e+03,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [3.2000e+01, 2.0503e+04, 1.5886e+03,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "#preprocessing: X = training and suspects is testing dataset\n",
    "suspects = suspects.drop(columns=['userID'])\n",
    "df_full_train = pd.DataFrame(df_encoded.drop(columns=['Credit_Mix']))\n",
    "df_full_test = pd.DataFrame(X)\n",
    "suspects_train = pd.DataFrame(suspects)\n",
    "\n",
    "df_full_train = torch.tensor(df_full_train.values, dtype=torch.float)\n",
    "df_full_test = torch.tensor(df_full_test.values, dtype=torch.float)\n",
    "suspects_train = torch.tensor(suspects.values, dtype=torch.float)\n",
    "\n",
    "print(df_full_train.shape, df_full_test.shape, suspects_train.shape, suspects_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=42, out_features=150, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=150, out_features=42, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define a new model here:\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Define the layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # Input layer to hidden layer\n",
    "        self.relu = nn.ReLU()  # ReLU activation function\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)  # Hidden layer to output layer\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.activation(self.linear1(x))   # Hidden layer: linear transformation + ReLU\n",
    "        y_pred = self.linear2(y_pred)               # Output layer: linear transformation\n",
    "        return y_pred\n",
    "\n",
    "# Define the input and output sizes\n",
    "input_size =  df_full_train.shape[1]\n",
    "output_size =  df_full_test.shape[1]\n",
    "hidden_size = 150  # 150 neurons in the hidden layer\n",
    "\n",
    "model2 = Net(input_size, hidden_size, output_size)\n",
    "print(model2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your MSE loss here:\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define your SGD optimizer for finding the weights of the network here:\n",
    "optimizer = torch.optim.SGD(model2.parameters(), lr=0.00005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Net' object has no attribute 'activation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/nathan/OneDrive/GitHub/DataScience_and_MachineLearning/Assignements/Part 4/Assignment_part_four.ipynb Cell 28\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nathan/OneDrive/GitHub/DataScience_and_MachineLearning/Assignements/Part%204/Assignment_part_four.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m losses1_test \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nathan/OneDrive/GitHub/DataScience_and_MachineLearning/Assignements/Part%204/Assignment_part_four.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m500\u001b[39m):                \u001b[39m# 500 iterations\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nathan/OneDrive/GitHub/DataScience_and_MachineLearning/Assignements/Part%204/Assignment_part_four.ipynb#X36sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nathan/OneDrive/GitHub/DataScience_and_MachineLearning/Assignements/Part%204/Assignment_part_four.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# Forward pass: compute prediction on training set\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/nathan/OneDrive/GitHub/DataScience_and_MachineLearning/Assignements/Part%204/Assignment_part_four.ipynb#X36sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m model2(df_full_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nathan/OneDrive/GitHub/DataScience_and_MachineLearning/Assignements/Part%204/Assignment_part_four.ipynb#X36sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# Compute loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nathan/OneDrive/GitHub/DataScience_and_MachineLearning/Assignements/Part%204/Assignment_part_four.ipynb#X36sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(y_pred, df_full_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/nathan/OneDrive/GitHub/DataScience_and_MachineLearning/Assignements/Part 4/Assignment_part_four.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nathan/OneDrive/GitHub/DataScience_and_MachineLearning/Assignements/Part%204/Assignment_part_four.ipynb#X36sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/nathan/OneDrive/GitHub/DataScience_and_MachineLearning/Assignements/Part%204/Assignment_part_four.ipynb#X36sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactivation(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear1(x))   \u001b[39m# Hidden layer: linear transformation + ReLU\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nathan/OneDrive/GitHub/DataScience_and_MachineLearning/Assignements/Part%204/Assignment_part_four.ipynb#X36sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear2(y_pred)               \u001b[39m# Output layer: linear transformation\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nathan/OneDrive/GitHub/DataScience_and_MachineLearning/Assignements/Part%204/Assignment_part_four.ipynb#X36sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m y_pred\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Net' object has no attribute 'activation'"
     ]
    }
   ],
   "source": [
    "# perform your training here\n",
    "losses1 = []\n",
    "losses1_test = []\n",
    "\n",
    "for t in range(500):                # 500 iterations\n",
    "\n",
    "    # Forward pass: compute prediction on training set\n",
    "    y_pred = model2(df_full_train)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(y_pred, df_full_test)\n",
    "    print(t, loss.item())\n",
    "    losses1.append(loss.item())\n",
    "    if torch.isnan(loss):\n",
    "        break\n",
    "\n",
    "    # Compute gradient\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Update\n",
    "    optimizer.step()\n",
    "\n",
    "    # Compute loss on test set\n",
    "    #losses1_test.append(criterion(model2(X_test), y_test).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Predict over the suspects dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict which users have a good credit score here:\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
