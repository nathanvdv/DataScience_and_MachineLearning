{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/michalis0/DataScience_and_MachineLearning/blob/master/Assignements/Part%203/Assignment_part_three.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZu-7QbP9muh"
      },
      "source": [
        "DSML investigation:\n",
        "\n",
        "You are part of the Suisse Impossible Mission Force, or SIMF for short. You need to uncover a rogue agent that is trying to steal sensitive information.\n",
        "\n",
        "Your mission, should you choose to accept it, is to find that agent before stealing any classified information. Good luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyL7WNdV9sWV"
      },
      "source": [
        "# Assignement part three\n",
        "### Due 15.10.2023\n",
        "\n",
        "We received new intelligence informing us that the rogue agent has a position with great responsibility.\n",
        "Use the table \"HR_Analytics.csv\" to create a classifier model that predicts the job role of a person. Use this model to predict the roles of the table of suspects \"suspect_HR_data.csv\".\n",
        "\n",
        "Retain only the list of suspects whose role indicates high responsibility.\n",
        "\n",
        "\n",
        "## Getting to know our data\n",
        "\n",
        "- BusinessTravel: The frequency of business travel for the employee. (Categorical)\n",
        "- DailyRate: The daily rate of pay for the employee. (Numerical)\n",
        "- DistanceFromHome: The distance from home in miles for the employee. (Numerical)\n",
        "- Education: The level of education achieved by the employee. (Categorical)\n",
        "- EmployeeCount: The total number of employees in the organization. (Numerical)\n",
        "- EmployeeNumber: A unique identifier for each employee profile. (Numerical)\n",
        "- EnvironmentSatisfaction: The employee's satisfaction with their work environment. (Categorical)\n",
        "- Gender: The gender of the employee. (Categorical)\n",
        "- HourlyRate: The hourly rate of pay for the employee. (Numerical)\n",
        "- JobInvolvement: The level of involvement required for the employee's job. (Categorical)\n",
        "- JobLevel: The job level of the employee. (Categorical)\n",
        "- JobSatisfaction: The employee's satisfaction with their job. (Categorical)\n",
        "- MonthlyIncome: The monthly income of the employee. (Numerical)\n",
        "- MonthlyRate: The monthly rate of pay for the employee. (Numerical)\n",
        "- NumCompaniesWorked: The number of companies the employee has worked for. (Numerical)\n",
        "- Over18: Whether or not the employee is over 18. (Categorical)\n",
        "- OverTime: Whether or not the employee works overtime. (Categorical)\n",
        "- PercentSalaryHike: The percentage of salary hike for the employee. (Numerical)\n",
        "- PerformanceRating: The performance rating of the employee. (Categorical)\n",
        "- RelationshipSatisfaction: The employee's satisfaction with their relationships. (Categorical)\n",
        "- StandardHours: The standard hours of work for the employee. (Numerical)\n",
        "- StockOptionLevel: The stock option level of the employee. (Numerical)\n",
        "- TotalWorkingYears: The total number of years the employee has worked. (Numerical)\n",
        "- TrainingTimesLastYear: The number of times the employee was taken for training in the last year. (Numerical)\n",
        "- WorkLifeBalance: The employee's perception of their work-life balance. (Categorical)\n",
        "- YearsAtCompany: The number of years the employee has been with the company. (Numerical)\n",
        "- YearsInCurrentRole: The number of years the employee has been in their current role. (Numerical)\n",
        "- YearsSinceLastPromotion: The number of years since the employee's last promotion. (Numerical)\n",
        "- YearsWithCurrManager: The number of years the employee has been with their current manager. (Numerical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XHhI95r5-tyD"
      },
      "outputs": [],
      "source": [
        "# Import required packages\n",
        "# Import required packages\n",
        "import  numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder , MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
        "from sklearn.pipeline import Pipeline\n",
        "%matplotlib inline\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/michalis0/DataScience_and_MachineLearning/master/Assignements/Part%203/data/HR_Analytics.csv\", index_col='Unnamed: 0')\n",
        "suspects = pd.read_csv(\"https://raw.githubusercontent.com/michalis0/DataScience_and_MachineLearning/master/Assignements/Part%203/data/suspects.csv\", index_col='Unnamed: 0')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg11L0cJfVM-"
      },
      "source": [
        "### Let's check the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0ri776pfc3j",
        "outputId": "2b729cfc-24b5-410a-ec2d-bb922dabb66e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1470 entries, 0 to 1469\n",
            "Data columns (total 28 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   BusinessTravel            1470 non-null   object\n",
            " 1   DailyRate                 1470 non-null   int64 \n",
            " 2   DistanceFromHome          1470 non-null   int64 \n",
            " 3   Education                 1470 non-null   int64 \n",
            " 4   EmployeeCount             1470 non-null   int64 \n",
            " 5   EmployeeNumber            1470 non-null   int64 \n",
            " 6   EnvironmentSatisfaction   1470 non-null   int64 \n",
            " 7   Gender                    1470 non-null   object\n",
            " 8   HourlyRate                1470 non-null   int64 \n",
            " 9   JobInvolvement            1470 non-null   int64 \n",
            " 10  JobLevel                  1470 non-null   int64 \n",
            " 11  JobSatisfaction           1470 non-null   int64 \n",
            " 12  MonthlyIncome             1470 non-null   int64 \n",
            " 13  MonthlyRate               1470 non-null   int64 \n",
            " 14  NumCompaniesWorked        1470 non-null   int64 \n",
            " 15  OverTime                  1470 non-null   object\n",
            " 16  PercentSalaryHike         1470 non-null   int64 \n",
            " 17  PerformanceRating         1470 non-null   int64 \n",
            " 18  RelationshipSatisfaction  1470 non-null   int64 \n",
            " 19  StandardHours             1470 non-null   int64 \n",
            " 20  StockOptionLevel          1470 non-null   int64 \n",
            " 21  TotalWorkingYears         1470 non-null   int64 \n",
            " 22  TrainingTimesLastYear     1470 non-null   int64 \n",
            " 23  WorkLifeBalance           1470 non-null   int64 \n",
            " 24  YearsAtCompany            1470 non-null   int64 \n",
            " 25  YearsInCurrentRole        1470 non-null   int64 \n",
            " 26  YearsSinceLastPromotion   1470 non-null   int64 \n",
            " 27  YearsWithCurrManager      1470 non-null   int64 \n",
            "dtypes: int64(25), object(3)\n",
            "memory usage: 333.0+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igq5I7pOm0SW"
      },
      "source": [
        "## 1. Define a pipeline that encodes features as follows:\n",
        "\n",
        "* Use one-hot encoding for `BusinessTravel`\n",
        "* Use label encoding for `Gender` and `OverTime`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "LV87NptOASo6",
        "outputId": "af8079be-c51b-4ca6-88f1-2e3da0b2f446"
      },
      "outputs": [],
      "source": [
        "def Pipeline(train: pd.DataFrame, test: pd.DataFrame):\n",
        "    # 1. One-hot encoding for BusinessTravel\n",
        "    train = pd.get_dummies(train, columns=['BusinessTravel'], prefix=['BusinessTravel'])\n",
        "    test = pd.get_dummies(test, columns=['BusinessTravel'], prefix=['BusinessTravel'])\n",
        "    #encoder = OneHotEncoder(drop='first', sparse = False)\n",
        "    #encoder.fit(train[['BusinessTravel']])\n",
        "    #train = encoder.transform(train[['BusinessTravel']])\n",
        "    #test = encoder.transform(test[['BusinessTravel']])\n",
        "    # 2. Label encoding for Gender and OverTime\n",
        "    label_encoders = {}\n",
        "    label_cols = ['Gender', 'OverTime']\n",
        "    for col in label_cols:\n",
        "        le = LabelEncoder()\n",
        "        train[col] = le.fit_transform(train[col])\n",
        "        test[col] = le.transform(test[col])\n",
        "        label_encoders[col] = le\n",
        "\n",
        "    boolean_columns = ['BusinessTravel_Non-Travel', 'BusinessTravel_Travel_Frequently', 'BusinessTravel_Travel_Rarely']\n",
        "\n",
        "    for column in boolean_columns:\n",
        "        train[column] = train[column].astype(int)\n",
        "        test[column] = test[column].astype(int)\n",
        "\n",
        "    # 3. Concatenate the datasets\n",
        "    #df_train = train.copy()\n",
        "    #df_test = test.copy()\n",
        "    combined_df = pd.concat([train, test], axis=0)\n",
        "\n",
        "    # 4. Apply Min-Max scaling fitted on the train dataset\n",
        "    numeric_cols = ['DailyRate', 'DistanceFromHome', 'HourlyRate', 'MonthlyIncome', 'MonthlyRate',\n",
        "                    'NumCompaniesWorked', 'PercentSalaryHike', 'StandardHours', 'StockOptionLevel',\n",
        "                    'TotalWorkingYears', 'TrainingTimesLastYear', 'YearsAtCompany',\n",
        "                    'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager']\n",
        "\n",
        "    #scaler = MinMaxScaler()\n",
        "    #df_train[numeric_cols] = scaler.fit_transform(df_train[numeric_cols])\n",
        "    #df_test[numeric_cols] = scaler.transform(df_test[numeric_cols])\n",
        "    scaler = MinMaxScaler()\n",
        "    combined_df[numeric_cols] = scaler.fit_transform(combined_df[numeric_cols])\n",
        "\n",
        "    # Split the concatenated dataset back into train and test sets\n",
        "    train_size = len(train)\n",
        "    df_train = combined_df[:train_size]\n",
        "    df_test = combined_df[train_size:]\n",
        "\n",
        "    return df_train, df_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Define your dependent variable y (\"JobLevel\") and your independent features X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      DailyRate  DistanceFromHome  Education  EmployeeCount  EmployeeNumber  \\\n",
            "0      0.715820          0.000000          2              1               1   \n",
            "1      0.126700          0.250000          1              1               2   \n",
            "2      0.909807          0.035714          2              1               4   \n",
            "3      0.923407          0.071429          4              1               5   \n",
            "4      0.350036          0.035714          1              1               7   \n",
            "...         ...               ...        ...            ...             ...   \n",
            "1465   0.559771          0.785714          2              1            2061   \n",
            "1466   0.365784          0.178571          1              1            2062   \n",
            "1467   0.037938          0.107143          3              1            2064   \n",
            "1468   0.659270          0.035714          3              1            2065   \n",
            "1469   0.376521          0.250000          3              1            2068   \n",
            "\n",
            "      EnvironmentSatisfaction  Gender  HourlyRate  JobInvolvement  JobLevel  \\\n",
            "0                           2       0    0.914286               3       2.0   \n",
            "1                           3       1    0.442857               2       2.0   \n",
            "2                           4       1    0.885714               2       1.0   \n",
            "3                           4       0    0.371429               3       1.0   \n",
            "4                           1       1    0.142857               3       1.0   \n",
            "...                       ...     ...         ...             ...       ...   \n",
            "1465                        3       1    0.157143               4       2.0   \n",
            "1466                        4       1    0.171429               2       3.0   \n",
            "1467                        2       1    0.814286               4       2.0   \n",
            "1468                        4       1    0.471429               2       2.0   \n",
            "1469                        2       1    0.742857               4       2.0   \n",
            "\n",
            "      ...  TotalWorkingYears  TrainingTimesLastYear  WorkLifeBalance  \\\n",
            "0     ...              0.200               0.000000                1   \n",
            "1     ...              0.250               0.500000                3   \n",
            "2     ...              0.175               0.500000                3   \n",
            "3     ...              0.200               0.500000                3   \n",
            "4     ...              0.150               0.500000                3   \n",
            "...   ...                ...                    ...              ...   \n",
            "1465  ...              0.425               0.500000                3   \n",
            "1466  ...              0.225               0.833333                3   \n",
            "1467  ...              0.150               0.000000                3   \n",
            "1468  ...              0.425               0.500000                2   \n",
            "1469  ...              0.150               0.500000                4   \n",
            "\n",
            "      YearsAtCompany  YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
            "0              0.150            0.222222                 0.000000   \n",
            "1              0.250            0.388889                 0.066667   \n",
            "2              0.000            0.000000                 0.000000   \n",
            "3              0.200            0.388889                 0.200000   \n",
            "4              0.050            0.111111                 0.133333   \n",
            "...              ...                 ...                      ...   \n",
            "1465           0.125            0.111111                 0.000000   \n",
            "1466           0.175            0.388889                 0.066667   \n",
            "1467           0.150            0.111111                 0.000000   \n",
            "1468           0.225            0.333333                 0.000000   \n",
            "1469           0.100            0.166667                 0.066667   \n",
            "\n",
            "      YearsWithCurrManager  BusinessTravel_Non-Travel  \\\n",
            "0                 0.294118                          0   \n",
            "1                 0.411765                          0   \n",
            "2                 0.000000                          0   \n",
            "3                 0.000000                          0   \n",
            "4                 0.117647                          0   \n",
            "...                    ...                        ...   \n",
            "1465              0.176471                          0   \n",
            "1466              0.411765                          0   \n",
            "1467              0.176471                          0   \n",
            "1468              0.470588                          0   \n",
            "1469              0.117647                          0   \n",
            "\n",
            "      BusinessTravel_Travel_Frequently  BusinessTravel_Travel_Rarely  \n",
            "0                                    0                             1  \n",
            "1                                    1                             0  \n",
            "2                                    0                             1  \n",
            "3                                    1                             0  \n",
            "4                                    0                             1  \n",
            "...                                ...                           ...  \n",
            "1465                                 1                             0  \n",
            "1466                                 0                             1  \n",
            "1467                                 0                             1  \n",
            "1468                                 1                             0  \n",
            "1469                                 0                             1  \n",
            "\n",
            "[1470 rows x 30 columns]      DailyRate  DistanceFromHome  Education  EmployeeCount  EmployeeNumber  \\\n",
            "0     0.715820          0.000000          2              1               1   \n",
            "1     0.126700          0.250000          1              1               2   \n",
            "2     0.909807          0.035714          2              1               4   \n",
            "3     0.923407          0.071429          4              1               5   \n",
            "4     0.350036          0.035714          1              1               7   \n",
            "..         ...               ...        ...            ...             ...   \n",
            "724   0.790265          0.571429          1              1            1009   \n",
            "725   0.372226          0.464286          4              1            1010   \n",
            "726   0.537581          0.000000          1              1            1011   \n",
            "727   0.132427          0.142857          2              1            1012   \n",
            "728   0.958482          0.571429          3              1            1013   \n",
            "\n",
            "     EnvironmentSatisfaction  Gender  HourlyRate  JobInvolvement  \\\n",
            "0                          2       0    0.914286               3   \n",
            "1                          3       1    0.442857               2   \n",
            "2                          4       1    0.885714               2   \n",
            "3                          4       0    0.371429               3   \n",
            "4                          1       1    0.142857               3   \n",
            "..                       ...     ...         ...             ...   \n",
            "724                        4       0    0.157143               2   \n",
            "725                        3       1    0.128571               2   \n",
            "726                        3       0    0.942857               3   \n",
            "727                        2       1    0.614286               3   \n",
            "728                        3       0    0.371429               3   \n",
            "\n",
            "     JobSatisfaction  ...  TrainingTimesLastYear  WorkLifeBalance  \\\n",
            "0                  4  ...               0.000000                1   \n",
            "1                  2  ...               0.500000                3   \n",
            "2                  3  ...               0.500000                3   \n",
            "3                  3  ...               0.500000                3   \n",
            "4                  2  ...               0.500000                3   \n",
            "..               ...  ...                    ...              ...   \n",
            "724                3  ...               1.000000                3   \n",
            "725                2  ...               0.333333                1   \n",
            "726                1  ...               0.166667                3   \n",
            "727                4  ...               0.333333                3   \n",
            "728                3  ...               0.333333                3   \n",
            "\n",
            "     YearsAtCompany  YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
            "0              0.15            0.222222                 0.000000   \n",
            "1              0.25            0.388889                 0.066667   \n",
            "2              0.00            0.000000                 0.000000   \n",
            "3              0.20            0.388889                 0.200000   \n",
            "4              0.05            0.111111                 0.133333   \n",
            "..              ...                 ...                      ...   \n",
            "724            0.10            0.111111                 0.200000   \n",
            "725            0.10            0.111111                 0.000000   \n",
            "726            0.10            0.166667                 0.000000   \n",
            "727            0.00            0.000000                 0.000000   \n",
            "728            0.25            0.388889                 0.000000   \n",
            "\n",
            "     YearsWithCurrManager  BusinessTravel_Non-Travel  \\\n",
            "0                0.294118                          0   \n",
            "1                0.411765                          0   \n",
            "2                0.000000                          0   \n",
            "3                0.000000                          0   \n",
            "4                0.117647                          0   \n",
            "..                    ...                        ...   \n",
            "724              0.117647                          0   \n",
            "725              0.117647                          0   \n",
            "726              0.176471                          0   \n",
            "727              0.000000                          1   \n",
            "728              0.470588                          0   \n",
            "\n",
            "     BusinessTravel_Travel_Frequently  BusinessTravel_Travel_Rarely    userID  \n",
            "0                                   0                             1  317991.0  \n",
            "1                                   1                             0  241892.0  \n",
            "2                                   0                             1  303376.0  \n",
            "3                                   1                             0  761992.0  \n",
            "4                                   0                             1  373318.0  \n",
            "..                                ...                           ...       ...  \n",
            "724                                 0                             1  458293.0  \n",
            "725                                 0                             1  218415.0  \n",
            "726                                 1                             0  173906.0  \n",
            "727                                 0                             0  178685.0  \n",
            "728                                 0                             1    2008.0  \n",
            "\n",
            "[729 rows x 30 columns]\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "df_train_processed, df_test_processed = Pipeline(df, suspects)\n",
        "df_train_processed = df_train_processed.dropna(axis=1)\n",
        "df_test_processed = df_test_processed.dropna(axis=1)\n",
        "print(df_train_processed, df_test_processed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX1tEH1j0g3R"
      },
      "source": [
        "## 2. Logistic Regression\n",
        "\n",
        "In this section we will use logistic regression to predict the JobLevel of the potential suspects.\n",
        "\n",
        "To do so you can reuse the pipeline created in part 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9B35IqVj0gL3"
      },
      "source": [
        "#### 2.1 Use logistic regression to predict the `JobLevel` based on all variables over the test set. \n",
        "You can use a test_size of 0.2 and random a random state of 42\n",
        "(use logistic regression with the lbfgs solver, 5 fold cross validation and max_iter = 100)\n",
        "\n",
        "Use only the HR analytics dataset to collect accurate insight on the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Fiex4f6y0rvD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nathan/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Your code here\n",
        "# Split the data into features (X) and target (y)\n",
        "y_train = df_train_processed['JobLevel']\n",
        "X_train = df_train_processed.drop(columns=['JobLevel'])\n",
        "\n",
        "# Split the data into training and testing sets with a test size of 0.2 and a random state of 42\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Initialize and train a logistic regression model\n",
        "logistic_regression_model = LogisticRegression(solver='lbfgs', max_iter=100)\n",
        "logistic_regression_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1. 1. 2. 2. 2. 1. 2. 2. 1. 2. 1. 2. 1. 2. 4. 3. 2. 1. 2. 1.\n",
            " 1. 2. 1. 1. 1. 2. 1. 1. 1. 1. 2. 2. 2. 1. 1. 1. 2. 1. 2. 2. 1. 2. 2. 1.\n",
            " 2. 1. 1. 1. 3. 1. 2. 1. 1. 1. 1. 1. 2. 1. 2. 1. 1. 2. 2. 1. 1. 1. 1. 4.\n",
            " 1. 2. 1. 2. 2. 1. 2. 1. 2. 1. 2. 1. 2. 1. 1. 2. 1. 1. 2. 1. 2. 1. 2. 2.\n",
            " 2. 2. 1. 2. 4. 2. 2. 1. 2. 2. 2. 2. 2. 2. 1. 2. 1. 1. 1. 2. 1. 4. 2. 1.\n",
            " 1. 1. 1. 2. 3. 1. 2. 2. 2. 2. 2. 1. 3. 2. 1. 2. 2. 2. 1. 2. 1. 1. 2. 1.\n",
            " 2. 2. 2. 1. 1. 1. 2. 2. 1. 1. 2. 1. 1. 1. 2. 1. 2. 2. 2. 1. 2. 2. 2. 2.\n",
            " 2. 2. 2. 3. 2. 1. 2. 1. 2. 1. 1. 1. 2. 1. 4. 1. 1. 1. 1. 2. 1. 1. 1. 4.\n",
            " 2. 1. 1. 1. 1. 2. 2. 2. 2. 1. 1. 2. 1. 1. 4. 2. 2. 4. 2. 1. 1. 1. 2. 2.\n",
            " 2. 1. 1. 2. 2. 1. 2. 2. 2. 1. 2. 2. 2. 1. 1. 1. 1. 2. 2. 1. 2. 1. 2. 2.\n",
            " 1. 2. 1. 1. 2. 1. 2. 1. 2. 1. 1. 2. 3. 1. 1. 1. 1. 1. 1. 2. 2. 2. 1. 2.\n",
            " 2. 1. 2. 2. 1. 1. 2. 1. 1. 1. 2. 2. 1. 1. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1.\n",
            " 1. 1. 2. 2. 1. 2.] [1. 1. 1. ... 2. 2. 2.]\n"
          ]
        }
      ],
      "source": [
        "y_test_pred = logistic_regression_model.predict(X_test)\n",
        "y_train_pred = logistic_regression_model.predict(X_train)\n",
        "print(y_test_pred, y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nathan/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nathan/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/nathan/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/nathan/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/nathan/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/nathan/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegressionCV(cv=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegressionCV</label><div class=\"sk-toggleable__content\"><pre>LogisticRegressionCV(cv=5)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegressionCV(cv=5)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_cv = LogisticRegressionCV(penalty='l2', solver='lbfgs', cv=5, max_iter=100)\n",
        "\n",
        "# Fit our model\n",
        "model_cv.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.1.2 Display the confusion matrix and the other accuracy measures seen in class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.3979591836734694\n",
            "0.48299319727891155\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Your code here\n",
        "confusion_cv = confusion_matrix(y_test, model_cv.predict(X_test))\n",
        "# Heatmap of confusion matrix\n",
        "sns.heatmap(confusion_cv, annot=True, cmap='Blues', fmt='.4g')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix with Cross Validation');\n",
        "#print(confusion_matrix(y_test, y_test))\n",
        "#print(confusion_matrix(y_train, y_train_pred))\n",
        "print(logistic_regression_model.score(X_test, y_test))\n",
        "print(logistic_regression_model.score(X_train, y_train))\n",
        "#model_proba = pd.DataFrame(logistic_regression_model.predict_proba(X_test),\n",
        "                           #columns=['Probability level 1', 'Probability level 2','Probability level 3', 'Probability level 4', 'Probability level 5'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of Logistic regression classifier on test set: 0.40\n",
            "Accuracy of Logistic regression classifier on training set: 0.48\n"
          ]
        }
      ],
      "source": [
        "# Accuracy on the test set\n",
        "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
        "     .format(logistic_regression_model.score(X_test, y_test)))\n",
        "\n",
        "# Accuracy on the training set\n",
        "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
        "     .format(logistic_regression_model.score(X_train, y_train)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of Logistic regression classifier on test set: 0.40\n",
            "Accuracy: 0.40\n",
            "Precision: 0.20\n",
            "Recall: 0.24\n",
            "F1 Score: 0.20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nathan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Accuracy on the test set\n",
        "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
        "     .format(logistic_regression_model.score(X_test, y_test)))\n",
        "accuracy = accuracy_score(y_test, y_test_pred)\n",
        "precision = precision_score(y_test, y_test_pred, average='macro')\n",
        "recall = recall_score(y_test, y_test_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZLOtpFN6UzN"
      },
      "source": [
        "#### 2.2 Predicting suspects Job Level\n",
        "Retrain a logistic regression model on the **full train dataset** and predict the JobLevel of the suspects. (do not forget to apply the pipeline)\n",
        "\n",
        "Training on part of the dataset is mainly usefull so that we get an idea of the results we should expect but also performing various optimisations.\n",
        "\n",
        "In order to get the best result possible it is advised to retrain on the entire set prior to making predictions.\n",
        "\n",
        "(use logistic regression with the lbfgs solver, 5 fold cross validation and max_iter = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EWFqT4LLGYnL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   DailyRate  DistanceFromHome  Education  EmployeeCount  EmployeeNumber  \\\n",
            "0   0.715820          0.000000          2              1               1   \n",
            "1   0.126700          0.250000          1              1               2   \n",
            "2   0.909807          0.035714          2              1               4   \n",
            "3   0.923407          0.071429          4              1               5   \n",
            "4   0.350036          0.035714          1              1               7   \n",
            "\n",
            "   EnvironmentSatisfaction  Gender  HourlyRate  JobInvolvement  JobLevel  ...  \\\n",
            "0                        2       0    0.914286               3       2.0  ...   \n",
            "1                        3       1    0.442857               2       2.0  ...   \n",
            "2                        4       1    0.885714               2       1.0  ...   \n",
            "3                        4       0    0.371429               3       1.0  ...   \n",
            "4                        1       1    0.142857               3       1.0  ...   \n",
            "\n",
            "   TotalWorkingYears  TrainingTimesLastYear  WorkLifeBalance  YearsAtCompany  \\\n",
            "0              0.200                    0.0                1            0.15   \n",
            "1              0.250                    0.5                3            0.25   \n",
            "2              0.175                    0.5                3            0.00   \n",
            "3              0.200                    0.5                3            0.20   \n",
            "4              0.150                    0.5                3            0.05   \n",
            "\n",
            "   YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  \\\n",
            "0            0.222222                 0.000000              0.294118   \n",
            "1            0.388889                 0.066667              0.411765   \n",
            "2            0.000000                 0.000000              0.000000   \n",
            "3            0.388889                 0.200000              0.000000   \n",
            "4            0.111111                 0.133333              0.117647   \n",
            "\n",
            "   BusinessTravel_Non-Travel  BusinessTravel_Travel_Frequently  \\\n",
            "0                          0                                 0   \n",
            "1                          0                                 1   \n",
            "2                          0                                 0   \n",
            "3                          0                                 1   \n",
            "4                          0                                 0   \n",
            "\n",
            "   BusinessTravel_Travel_Rarely  \n",
            "0                             1  \n",
            "1                             0  \n",
            "2                             1  \n",
            "3                             0  \n",
            "4                             1  \n",
            "\n",
            "[5 rows x 30 columns]    DailyRate  DistanceFromHome  Education  EmployeeCount  EmployeeNumber  \\\n",
            "0   0.715820          0.000000          2              1               1   \n",
            "1   0.126700          0.250000          1              1               2   \n",
            "2   0.909807          0.035714          2              1               4   \n",
            "3   0.923407          0.071429          4              1               5   \n",
            "4   0.350036          0.035714          1              1               7   \n",
            "\n",
            "   EnvironmentSatisfaction  Gender  HourlyRate  JobInvolvement  \\\n",
            "0                        2       0    0.914286               3   \n",
            "1                        3       1    0.442857               2   \n",
            "2                        4       1    0.885714               2   \n",
            "3                        4       0    0.371429               3   \n",
            "4                        1       1    0.142857               3   \n",
            "\n",
            "   JobSatisfaction  ...  TrainingTimesLastYear  WorkLifeBalance  \\\n",
            "0                4  ...                    0.0                1   \n",
            "1                2  ...                    0.5                3   \n",
            "2                3  ...                    0.5                3   \n",
            "3                3  ...                    0.5                3   \n",
            "4                2  ...                    0.5                3   \n",
            "\n",
            "   YearsAtCompany  YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
            "0            0.15            0.222222                 0.000000   \n",
            "1            0.25            0.388889                 0.066667   \n",
            "2            0.00            0.000000                 0.000000   \n",
            "3            0.20            0.388889                 0.200000   \n",
            "4            0.05            0.111111                 0.133333   \n",
            "\n",
            "   YearsWithCurrManager  BusinessTravel_Non-Travel  \\\n",
            "0              0.294118                          0   \n",
            "1              0.411765                          0   \n",
            "2              0.000000                          0   \n",
            "3              0.000000                          0   \n",
            "4              0.117647                          0   \n",
            "\n",
            "   BusinessTravel_Travel_Frequently  BusinessTravel_Travel_Rarely    userID  \n",
            "0                                 0                             1  317991.0  \n",
            "1                                 1                             0  241892.0  \n",
            "2                                 0                             1  303376.0  \n",
            "3                                 1                             0  761992.0  \n",
            "4                                 0                             1  373318.0  \n",
            "\n",
            "[5 rows x 30 columns]\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "preprocessed_train, preprocessed_test = Pipeline(df, suspects)\n",
        "preprocessed_train = preprocessed_train.dropna(axis=1)\n",
        "preprocessed_test = preprocessed_test.dropna(axis=1)\n",
        "print(preprocessed_train.head(),preprocessed_test.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "M1AUaZVVGgc0"
      },
      "outputs": [],
      "source": [
        "preprocessed_test = preprocessed_test.drop(columns=['userID'])\n",
        "X = preprocessed_train.drop(columns=['JobLevel'])\n",
        "y = preprocessed_train['JobLevel']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLvdBAyRGmlf",
        "outputId": "ac3cd035-9fc9-47d6-a312-dce00d298192"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nathan/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/nathan/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/nathan/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/nathan/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/nathan/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision Scores for Each Fold: [0.46262208 0.38604832 0.48628685 0.6170024  0.38515671]\n",
            "Mean Precision: 0.4674232708924582\n",
            "[2. 2. 1. 1. 1. 1. 1. 1. 2. 2. 1. 2. 1. 1. 1. 3. 1. 1. 3. 1. 1. 1. 3. 1.\n",
            " 1. 3. 1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 4. 2. 1.\n",
            " 2. 1. 2. 1. 1. 2. 2. 3. 2. 1. 2. 2. 2. 2. 4. 3. 3. 3. 1. 2. 1. 1. 2. 1.\n",
            " 1. 2. 1. 2. 2. 2. 3. 1. 2. 1. 2. 2. 1. 2. 1. 1. 2. 2. 3. 3. 2. 3. 2. 3.\n",
            " 1. 1. 4. 2. 1. 1. 1. 2. 2. 3. 4. 2. 1. 1. 3. 2. 4. 1. 1. 2. 3. 2. 1. 3.\n",
            " 2. 2. 2. 3. 2. 1. 4. 1. 1. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 1. 1.\n",
            " 2. 1. 1. 3. 1. 1. 2. 2. 1. 2. 2. 2. 1. 1. 3. 1. 1. 1. 1. 2. 1. 3. 2. 3.\n",
            " 2. 1. 1. 1. 2. 2. 2. 2. 1. 1. 3. 1. 1. 1. 1. 1. 1. 2. 3. 4. 2. 3. 5. 1.\n",
            " 1. 1. 3. 2. 1. 2. 1. 2. 1. 2. 1. 2. 2. 2. 1. 1. 2. 2. 3. 2. 2. 3. 1. 2.\n",
            " 2. 1. 3. 2. 2. 1. 2. 3. 1. 1. 2. 3. 2. 1. 1. 3. 1. 4. 2. 3. 2. 4. 1. 1.\n",
            " 1. 1. 1. 2. 5. 2. 1. 2. 1. 1. 2. 3. 1. 2. 1. 1. 2. 3. 1. 1. 1. 2. 1. 4.\n",
            " 1. 1. 2. 2. 3. 2. 5. 3. 1. 2. 1. 2. 3. 2. 1. 3. 3. 2. 2. 2. 1. 2. 1. 2.\n",
            " 1. 1. 3. 2. 1. 2. 1. 3. 1. 2. 1. 2. 3. 1. 1. 2. 2. 2. 2. 3. 2. 1. 1. 3.\n",
            " 1. 3. 3. 2. 3. 2. 1. 3. 1. 2. 2. 1. 2. 3. 3. 1. 1. 3. 1. 2. 2. 2. 2. 1.\n",
            " 1. 1. 2. 2. 2. 3. 2. 2. 2. 1. 2. 1. 3. 1. 1. 1. 2. 2. 2. 2. 1. 1. 1. 3.\n",
            " 1. 2. 1. 1. 2. 1. 2. 2. 2. 1. 1. 1. 2. 1. 2. 2. 2. 1. 2. 4. 1. 1. 1. 1.\n",
            " 2. 1. 2. 2. 1. 3. 3. 1. 3. 2. 2. 1. 1. 1. 2. 1. 3. 4. 2. 2. 2. 1. 2. 1.\n",
            " 4. 2. 2. 4. 2. 2. 1. 1. 1. 3. 1. 2. 2. 1. 1. 2. 3. 3. 2. 3. 2. 4. 2. 2.\n",
            " 2. 2. 2. 3. 2. 1. 2. 2. 2. 1. 2. 1. 2. 4. 2. 2. 3. 2. 2. 2. 2. 1. 2. 2.\n",
            " 2. 1. 2. 2. 1. 1. 2. 1. 2. 3. 3. 2. 2. 2. 1. 2. 2. 3. 1. 1. 1. 4. 2. 1.\n",
            " 1. 1. 1. 1. 2. 1. 1. 1. 1. 3. 1. 2. 3. 2. 1. 1. 1. 3. 1. 1. 2. 1. 3. 2.\n",
            " 1. 1. 2. 1. 3. 2. 2. 2. 1. 1. 2. 1. 1. 1. 1. 2. 2. 1. 1. 2. 3. 2. 2. 2.\n",
            " 2. 2. 2. 3. 2. 2. 3. 4. 2. 2. 5. 1. 2. 2. 1. 2. 4. 2. 1. 1. 2. 1. 1. 2.\n",
            " 3. 1. 2. 1. 1. 1. 2. 1. 1. 5. 2. 2. 2. 1. 2. 1. 3. 2. 2. 1. 3. 1. 1. 2.\n",
            " 1. 1. 2. 1. 1. 1. 2. 2. 4. 1. 1. 2. 5. 1. 2. 2. 3. 2. 2. 3. 1. 2. 1. 2.\n",
            " 2. 1. 1. 1. 2. 2. 1. 2. 2. 3. 3. 2. 1. 1. 2. 1. 3. 2. 1. 2. 1. 3. 1. 2.\n",
            " 3. 2. 2. 3. 2. 1. 1. 1. 1. 1. 1. 3. 2. 1. 3. 1. 1. 2. 1. 2. 1. 2. 2. 3.\n",
            " 2. 3. 2. 2. 2. 3. 2. 1. 1. 2. 1. 1. 1. 1. 1. 1. 2. 1. 1. 2. 1. 1. 1. 1.\n",
            " 2. 1. 3. 2. 2. 3. 1. 2. 1. 3. 1. 1. 2. 2. 2. 2. 1. 1. 2. 1. 2. 3. 1. 3.\n",
            " 2. 1. 1. 3. 1. 3. 2. 2. 2. 2. 2. 2. 2. 1. 3. 1. 1. 1. 3. 1. 3. 2. 2. 1.\n",
            " 1. 3. 1. 2. 2. 1. 1. 1. 3.]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nathan/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "model_full = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "precision_scorer = make_scorer(precision_score, average = 'macro')\n",
        "precision_scores = cross_val_score(model_full, X, y, cv=kf, scoring=precision_scorer)\n",
        "print(\"Precision Scores for Each Fold:\", precision_scores)\n",
        "print(\"Mean Precision:\", precision_scores.mean())\n",
        "\n",
        "# Retrain the model on the entire train dataset\n",
        "model_full.fit(X, y)\n",
        "\n",
        "# Make predictions on the test dataset\n",
        "y_pred = model_full.predict(preprocessed_test)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3aZt3WmEADO"
      },
      "source": [
        "## 3. Decision tree\n",
        "\n",
        "In this section we will use the decision tree model to predict the JobLevel of the potential suspects.\n",
        "\n",
        "To do so you can reuse the pipeline created in part 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ftteDGoEnSH"
      },
      "source": [
        "#### 3.1 Use Decision Tree classifier to predict the JobLevel based on all variables. Display the confusion matrix and the other accuracy measures seen in class.\n",
        "You can use a test_size of 0.2 and random a random state of 42\n",
        "\n",
        "The max depth for the decision tree can be 5\n",
        "\n",
        "\n",
        "Use only the HR analytics dataset to collect accurate insight on the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SF2_J7iAGdwW"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "y_train = df_train_processed['JobLevel']\n",
        "X_train = df_train_processed.drop(columns=['JobLevel'])\n",
        "\n",
        "# Split the data into training and testing sets with a test size of 0.2 and a random state of 42\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9jZxj5KFGhOi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9149659863945578\n",
            "0.9328231292517006\n"
          ]
        }
      ],
      "source": [
        "clf = DecisionTreeClassifier(max_depth=5)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "print(clf.score(X_test, y_test))\n",
        "print(clf.score(X_train, y_train))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JdPakTjxGoSf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2. 2. 1. 3. 2. 1. 1. 1. 3. 1. 1. 3. 2. 1. 1. 2. 2. 1. 3. 4. 1. 2. 2. 2.\n",
            " 2. 5. 1. 2. 1. 2. 2. 2. 2. 3. 2. 3. 4. 1. 1. 1. 3. 2. 2. 1. 1. 2. 3. 2.\n",
            " 2. 1. 4. 2. 5. 2. 1. 2. 1. 2. 2. 2. 3. 1. 3. 4. 2. 2. 2. 2. 1. 4. 2. 5.\n",
            " 3. 2. 2. 4. 2. 2. 3. 3. 5. 2. 4. 1. 3. 1. 3. 2. 2. 2. 2. 1. 3. 1. 3. 3.\n",
            " 3. 2. 2. 3. 5. 3. 3. 1. 3. 3. 2. 2. 3. 5. 2. 2. 2. 2. 1. 1. 2. 3. 4. 1.\n",
            " 1. 3. 1. 3. 2. 1. 2. 3. 2. 2. 1. 1. 3. 2. 2. 2. 1. 3. 1. 4. 1. 3. 2. 3.\n",
            " 4. 1. 2. 1. 1. 2. 2. 3. 2. 1. 2. 2. 2. 1. 5. 1. 2. 2. 2. 1. 1. 2. 1. 1.\n",
            " 4. 3. 2. 4. 1. 1. 2. 1. 2. 3. 3. 1. 3. 2. 5. 3. 3. 1. 3. 3. 3. 2. 2. 3.\n",
            " 3. 2. 2. 1. 1. 5. 2. 2. 1. 2. 2. 5. 4. 1. 3. 1. 1. 5. 3. 1. 1. 3. 3. 1.\n",
            " 2. 2. 2. 3. 1. 1. 3. 2. 2. 1. 2. 2. 3. 1. 2. 2. 5. 3. 2. 1. 2. 1. 4. 5.\n",
            " 1. 2. 2. 5. 3. 2. 1. 2. 2. 2. 2. 5. 5. 2. 2. 2. 1. 1. 1. 4. 2. 1. 1. 2.\n",
            " 2. 3. 5. 3. 2. 2. 1. 5. 2. 2. 3. 2. 1. 2. 2. 3. 2. 2. 1. 3. 4. 1. 2. 1.\n",
            " 2. 2. 2. 4. 2. 1.]\n"
          ]
        }
      ],
      "source": [
        "y_dct_pred = clf.predict(X_test)\n",
        "print(y_dct_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "h0yvnp5kG7gL",
        "outputId": "c214442b-e40b-4720-e22b-b0c973e05413"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.2 Display the confusion matrix and the other accuracy measures seen in class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBoU-eWcImA6",
        "outputId": "09772bec-901f-43fd-92a5-7d0003606ad0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[ 75   8   0   0   0]\n",
            " [  6 111   6   0   0]\n",
            " [  0   0  49   1   0]\n",
            " [  0   0   4  16   0]\n",
            " [  0   0   0   0  18]]\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "confusion_mat = confusion_matrix(y_test, y_dct_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yWTbfrsIq73",
        "outputId": "e3e21cf7-a529-4097-ec53-a25d577f0132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.91\n",
            "Precision: 0.92\n",
            "Recall: 0.91\n",
            "F1 Score: 0.91\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(y_test, y_dct_pred)\n",
        "precision = precision_score(y_test, y_dct_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_dct_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_dct_pred, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcnzdNuRIxZr",
        "outputId": "573973fa-171d-4ad0-b771-3be3b4ec157e"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtdHTSOfJZhf"
      },
      "source": [
        "#### 3.2 Predicting suspects Job Level according to the decision tree\n",
        "Retrain a decision tree model on the full train dataset and predict the JobLevel of the suspects. \n",
        "\n",
        "Training on part of the dataset is mainly usefull so that we get an idea of the results we should expect but also performing various optimisations.\n",
        "\n",
        "In order to get the best result possible it is advised to retrain on the entire set prior to making predictions.\n",
        "\n",
        "The max depth for the decision tree can be 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "lK6R3NyIJj9T",
        "outputId": "72d4fbac-57d3-48d2-a59a-301168fcf127"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   DailyRate  DistanceFromHome  Education  EmployeeCount  EmployeeNumber  \\\n",
            "0   0.715820          0.000000          2              1               1   \n",
            "1   0.126700          0.250000          1              1               2   \n",
            "2   0.909807          0.035714          2              1               4   \n",
            "3   0.923407          0.071429          4              1               5   \n",
            "4   0.350036          0.035714          1              1               7   \n",
            "\n",
            "   EnvironmentSatisfaction  Gender  HourlyRate  JobInvolvement  JobLevel  ...  \\\n",
            "0                        2       0    0.914286               3       2.0  ...   \n",
            "1                        3       1    0.442857               2       2.0  ...   \n",
            "2                        4       1    0.885714               2       1.0  ...   \n",
            "3                        4       0    0.371429               3       1.0  ...   \n",
            "4                        1       1    0.142857               3       1.0  ...   \n",
            "\n",
            "   TotalWorkingYears  TrainingTimesLastYear  WorkLifeBalance  YearsAtCompany  \\\n",
            "0              0.200                    0.0                1            0.15   \n",
            "1              0.250                    0.5                3            0.25   \n",
            "2              0.175                    0.5                3            0.00   \n",
            "3              0.200                    0.5                3            0.20   \n",
            "4              0.150                    0.5                3            0.05   \n",
            "\n",
            "   YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  \\\n",
            "0            0.222222                 0.000000              0.294118   \n",
            "1            0.388889                 0.066667              0.411765   \n",
            "2            0.000000                 0.000000              0.000000   \n",
            "3            0.388889                 0.200000              0.000000   \n",
            "4            0.111111                 0.133333              0.117647   \n",
            "\n",
            "   BusinessTravel_Non-Travel  BusinessTravel_Travel_Frequently  \\\n",
            "0                          0                                 0   \n",
            "1                          0                                 1   \n",
            "2                          0                                 0   \n",
            "3                          0                                 1   \n",
            "4                          0                                 0   \n",
            "\n",
            "   BusinessTravel_Travel_Rarely  \n",
            "0                             1  \n",
            "1                             0  \n",
            "2                             1  \n",
            "3                             0  \n",
            "4                             1  \n",
            "\n",
            "[5 rows x 30 columns]    DailyRate  DistanceFromHome  Education  EmployeeCount  EmployeeNumber  \\\n",
            "0   0.715820          0.000000          2              1               1   \n",
            "1   0.126700          0.250000          1              1               2   \n",
            "2   0.909807          0.035714          2              1               4   \n",
            "3   0.923407          0.071429          4              1               5   \n",
            "4   0.350036          0.035714          1              1               7   \n",
            "\n",
            "   EnvironmentSatisfaction  Gender  HourlyRate  JobInvolvement  \\\n",
            "0                        2       0    0.914286               3   \n",
            "1                        3       1    0.442857               2   \n",
            "2                        4       1    0.885714               2   \n",
            "3                        4       0    0.371429               3   \n",
            "4                        1       1    0.142857               3   \n",
            "\n",
            "   JobSatisfaction  ...  TrainingTimesLastYear  WorkLifeBalance  \\\n",
            "0                4  ...                    0.0                1   \n",
            "1                2  ...                    0.5                3   \n",
            "2                3  ...                    0.5                3   \n",
            "3                3  ...                    0.5                3   \n",
            "4                2  ...                    0.5                3   \n",
            "\n",
            "   YearsAtCompany  YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
            "0            0.15            0.222222                 0.000000   \n",
            "1            0.25            0.388889                 0.066667   \n",
            "2            0.00            0.000000                 0.000000   \n",
            "3            0.20            0.388889                 0.200000   \n",
            "4            0.05            0.111111                 0.133333   \n",
            "\n",
            "   YearsWithCurrManager  BusinessTravel_Non-Travel  \\\n",
            "0              0.294118                          0   \n",
            "1              0.411765                          0   \n",
            "2              0.000000                          0   \n",
            "3              0.000000                          0   \n",
            "4              0.117647                          0   \n",
            "\n",
            "   BusinessTravel_Travel_Frequently  BusinessTravel_Travel_Rarely    userID  \n",
            "0                                 0                             1  317991.0  \n",
            "1                                 1                             0  241892.0  \n",
            "2                                 0                             1  303376.0  \n",
            "3                                 1                             0  761992.0  \n",
            "4                                 0                             1  373318.0  \n",
            "\n",
            "[5 rows x 30 columns]\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "preprocessed_train, preprocessed_test = Pipeline(df, suspects)\n",
        "preprocessed_train = preprocessed_train.dropna(axis=1)\n",
        "preprocessed_test = preprocessed_test.dropna(axis=1)\n",
        "print(preprocessed_train.head(),preprocessed_test.head())\n",
        "preprocessed_test = preprocessed_test.drop(columns=['userID'])\n",
        "X = preprocessed_train.drop(columns=['JobLevel'])\n",
        "y = preprocessed_train['JobLevel']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2q6DRAgJn87",
        "outputId": "2f46358e-8a38-46e2-e89f-3d990919a4a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2. 2. 1. 1. 1. 1. 2. 1. 3. 2. 1. 2. 1. 1. 1. 3. 1. 1. 4. 1. 2. 1. 3. 1.\n",
            " 1. 5. 1. 2. 3. 5. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 1. 1. 1. 3. 2. 5. 2. 1.\n",
            " 2. 1. 3. 1. 2. 3. 2. 3. 3. 2. 2. 2. 2. 2. 5. 3. 3. 4. 2. 3. 1. 1. 2. 1.\n",
            " 1. 2. 1. 2. 2. 3. 3. 2. 2. 1. 3. 2. 2. 3. 1. 2. 2. 3. 3. 5. 2. 3. 2. 3.\n",
            " 2. 2. 4. 2. 1. 1. 1. 2. 2. 5. 5. 2. 1. 1. 3. 2. 4. 1. 2. 3. 3. 3. 1. 4.\n",
            " 2. 2. 1. 5. 2. 1. 3. 1. 1. 2. 2. 3. 2. 3. 1. 2. 3. 2. 2. 2. 2. 1. 2. 1.\n",
            " 2. 1. 1. 4. 1. 1. 2. 3. 1. 2. 3. 2. 2. 2. 3. 1. 1. 1. 1. 3. 1. 5. 2. 3.\n",
            " 3. 1. 1. 1. 1. 2. 2. 2. 1. 1. 3. 1. 1. 2. 1. 1. 2. 1. 5. 5. 3. 4. 5. 1.\n",
            " 2. 1. 4. 1. 2. 2. 2. 2. 2. 2. 1. 2. 2. 3. 1. 1. 2. 3. 3. 3. 2. 3. 1. 3.\n",
            " 2. 1. 3. 2. 2. 1. 3. 3. 2. 1. 2. 3. 3. 1. 1. 5. 1. 5. 1. 4. 1. 5. 1. 1.\n",
            " 1. 2. 2. 2. 5. 3. 1. 2. 1. 2. 3. 3. 1. 2. 2. 2. 1. 5. 1. 1. 2. 2. 2. 4.\n",
            " 1. 2. 2. 2. 3. 1. 5. 3. 1. 2. 1. 3. 3. 2. 2. 5. 4. 2. 2. 2. 2. 1. 1. 2.\n",
            " 1. 1. 5. 2. 1. 2. 1. 3. 1. 3. 1. 2. 4. 1. 2. 2. 3. 2. 2. 3. 2. 2. 2. 3.\n",
            " 1. 3. 4. 1. 4. 2. 1. 2. 2. 3. 2. 1. 2. 3. 5. 2. 2. 5. 2. 2. 2. 3. 1. 2.\n",
            " 1. 1. 2. 2. 2. 3. 3. 2. 3. 1. 2. 2. 4. 2. 1. 1. 3. 2. 2. 2. 2. 1. 2. 3.\n",
            " 2. 1. 1. 1. 1. 2. 2. 3. 2. 1. 1. 1. 2. 1. 2. 3. 2. 1. 2. 4. 2. 1. 1. 1.\n",
            " 3. 1. 1. 2. 1. 5. 4. 1. 5. 2. 2. 1. 2. 2. 2. 1. 5. 3. 2. 3. 2. 2. 3. 1.\n",
            " 4. 2. 2. 5. 2. 2. 1. 1. 1. 5. 1. 1. 3. 1. 1. 3. 4. 4. 1. 3. 2. 4. 1. 2.\n",
            " 1. 3. 3. 3. 1. 1. 3. 3. 3. 1. 3. 1. 2. 4. 2. 2. 3. 1. 2. 3. 2. 1. 2. 4.\n",
            " 3. 1. 3. 2. 2. 2. 2. 1. 3. 3. 4. 3. 2. 2. 1. 3. 2. 5. 1. 2. 1. 5. 1. 1.\n",
            " 1. 1. 2. 2. 2. 1. 3. 1. 2. 4. 1. 2. 4. 2. 1. 1. 1. 5. 1. 2. 2. 1. 3. 1.\n",
            " 2. 1. 3. 2. 2. 3. 3. 3. 1. 1. 1. 1. 1. 2. 2. 1. 3. 2. 2. 1. 3. 2. 2. 2.\n",
            " 2. 3. 3. 3. 2. 3. 4. 5. 2. 3. 5. 1. 1. 3. 3. 1. 4. 2. 1. 1. 2. 2. 1. 2.\n",
            " 3. 1. 2. 1. 2. 2. 2. 1. 2. 4. 1. 2. 2. 1. 2. 2. 5. 3. 2. 2. 5. 2. 1. 2.\n",
            " 2. 1. 2. 2. 1. 1. 2. 2. 5. 1. 1. 1. 4. 1. 3. 2. 5. 2. 1. 5. 1. 2. 2. 1.\n",
            " 2. 2. 2. 1. 2. 2. 1. 3. 2. 5. 3. 3. 1. 1. 1. 1. 5. 2. 1. 2. 1. 2. 2. 1.\n",
            " 3. 3. 2. 5. 2. 2. 2. 1. 1. 1. 2. 3. 1. 1. 5. 1. 1. 2. 1. 2. 1. 1. 3. 3.\n",
            " 1. 5. 2. 1. 3. 5. 2. 1. 1. 1. 1. 2. 1. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1.\n",
            " 2. 1. 3. 1. 2. 3. 1. 2. 2. 3. 1. 1. 3. 2. 2. 1. 1. 1. 2. 1. 2. 3. 2. 3.\n",
            " 2. 1. 2. 4. 1. 4. 3. 2. 3. 3. 3. 2. 2. 1. 4. 1. 1. 1. 4. 2. 5. 1. 1. 2.\n",
            " 1. 4. 1. 3. 2. 1. 2. 1. 3.]\n"
          ]
        }
      ],
      "source": [
        "model_trained_full = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "model_trained_full.fit(X, y)\n",
        "\n",
        "predidctions_full = model_trained_full.predict(preprocessed_test)\n",
        "print(predidctions_full)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. kNN\n",
        "\n",
        "In this section we will use the kNN model to predict the JobLevel of the potential suspects.\n",
        "\n",
        "To do so you can reuse the DataFrame created in part 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.1. Use `GridSearchCV` from *sklearn.model_selection* to find the best value of `k` that should be used for the K-Nearest Neighbours (KNN) algorithm.\n",
        "\n",
        "\n",
        "*   Use a range value of hyperparmeter `k` from 1 to 8. This range is a parameter used by the `GridSearchCV` to define the best value of `k`.\n",
        "*   Set the cross-validation to 5 folds.\n",
        "*   Set `scoring='accuracy', 'return_train_score=False', verbose=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   DailyRate  DistanceFromHome  Education  EmployeeCount  EmployeeNumber  \\\n",
            "0   0.715820          0.000000          2              1               1   \n",
            "1   0.126700          0.250000          1              1               2   \n",
            "2   0.909807          0.035714          2              1               4   \n",
            "3   0.923407          0.071429          4              1               5   \n",
            "4   0.350036          0.035714          1              1               7   \n",
            "\n",
            "   EnvironmentSatisfaction  Gender  HourlyRate  JobInvolvement  JobLevel  ...  \\\n",
            "0                        2       0    0.914286               3       2.0  ...   \n",
            "1                        3       1    0.442857               2       2.0  ...   \n",
            "2                        4       1    0.885714               2       1.0  ...   \n",
            "3                        4       0    0.371429               3       1.0  ...   \n",
            "4                        1       1    0.142857               3       1.0  ...   \n",
            "\n",
            "   TotalWorkingYears  TrainingTimesLastYear  WorkLifeBalance  YearsAtCompany  \\\n",
            "0              0.200                    0.0                1            0.15   \n",
            "1              0.250                    0.5                3            0.25   \n",
            "2              0.175                    0.5                3            0.00   \n",
            "3              0.200                    0.5                3            0.20   \n",
            "4              0.150                    0.5                3            0.05   \n",
            "\n",
            "   YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  \\\n",
            "0            0.222222                 0.000000              0.294118   \n",
            "1            0.388889                 0.066667              0.411765   \n",
            "2            0.000000                 0.000000              0.000000   \n",
            "3            0.388889                 0.200000              0.000000   \n",
            "4            0.111111                 0.133333              0.117647   \n",
            "\n",
            "   BusinessTravel_Non-Travel  BusinessTravel_Travel_Frequently  \\\n",
            "0                          0                                 0   \n",
            "1                          0                                 1   \n",
            "2                          0                                 0   \n",
            "3                          0                                 1   \n",
            "4                          0                                 0   \n",
            "\n",
            "   BusinessTravel_Travel_Rarely  \n",
            "0                             1  \n",
            "1                             0  \n",
            "2                             1  \n",
            "3                             0  \n",
            "4                             1  \n",
            "\n",
            "[5 rows x 30 columns]    DailyRate  DistanceFromHome  Education  EmployeeCount  EmployeeNumber  \\\n",
            "0   0.715820          0.000000          2              1               1   \n",
            "1   0.126700          0.250000          1              1               2   \n",
            "2   0.909807          0.035714          2              1               4   \n",
            "3   0.923407          0.071429          4              1               5   \n",
            "4   0.350036          0.035714          1              1               7   \n",
            "\n",
            "   EnvironmentSatisfaction  Gender  HourlyRate  JobInvolvement  \\\n",
            "0                        2       0    0.914286               3   \n",
            "1                        3       1    0.442857               2   \n",
            "2                        4       1    0.885714               2   \n",
            "3                        4       0    0.371429               3   \n",
            "4                        1       1    0.142857               3   \n",
            "\n",
            "   JobSatisfaction  ...  TrainingTimesLastYear  WorkLifeBalance  \\\n",
            "0                4  ...                    0.0                1   \n",
            "1                2  ...                    0.5                3   \n",
            "2                3  ...                    0.5                3   \n",
            "3                3  ...                    0.5                3   \n",
            "4                2  ...                    0.5                3   \n",
            "\n",
            "   YearsAtCompany  YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
            "0            0.15            0.222222                 0.000000   \n",
            "1            0.25            0.388889                 0.066667   \n",
            "2            0.00            0.000000                 0.000000   \n",
            "3            0.20            0.388889                 0.200000   \n",
            "4            0.05            0.111111                 0.133333   \n",
            "\n",
            "   YearsWithCurrManager  BusinessTravel_Non-Travel  \\\n",
            "0              0.294118                          0   \n",
            "1              0.411765                          0   \n",
            "2              0.000000                          0   \n",
            "3              0.000000                          0   \n",
            "4              0.117647                          0   \n",
            "\n",
            "   BusinessTravel_Travel_Frequently  BusinessTravel_Travel_Rarely    userID  \n",
            "0                                 0                             1  317991.0  \n",
            "1                                 1                             0  241892.0  \n",
            "2                                 0                             1  303376.0  \n",
            "3                                 1                             0  761992.0  \n",
            "4                                 0                             1  373318.0  \n",
            "\n",
            "[5 rows x 30 columns]\n"
          ]
        }
      ],
      "source": [
        "# Train test split\n",
        "preprocessed_train, preprocessed_test = Pipeline(df, suspects)\n",
        "preprocessed_train = preprocessed_train.dropna(axis=1)\n",
        "preprocessed_test = preprocessed_test.dropna(axis=1)\n",
        "print(preprocessed_train.head(),preprocessed_test.head())\n",
        "preprocessed_test = preprocessed_test.drop(columns=['userID'])\n",
        "X = preprocessed_train.drop(columns=['JobLevel'])\n",
        "y = preprocessed_train['JobLevel']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
              "             param_grid={&#x27;n_neighbors&#x27;: [1, 2, 3, 4, 5, 6, 7, 8]},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
              "             param_grid={&#x27;n_neighbors&#x27;: [1, 2, 3, 4, 5, 6, 7, 8]},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
              "             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8]},\n",
              "             scoring='accuracy', verbose=1)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the best parameters\n",
        "param_grid = {'n_neighbors': list(range(1, 9))}\n",
        "\n",
        "# Use GridSearchCV to find the best k value with 5-fold cross-validation\n",
        "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy', return_train_score=False, verbose=1)\n",
        "grid_search.fit(X, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best k value: 8\n"
          ]
        }
      ],
      "source": [
        "# What is the best score?\n",
        "best_k = grid_search.best_params_['n_neighbors']\n",
        "print(\"Best k value:\", best_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5034013605442177\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.43      0.76      0.55        83\n",
            "         2.0       0.61      0.59      0.60       123\n",
            "         3.0       0.50      0.26      0.34        50\n",
            "         4.0       0.00      0.00      0.00        20\n",
            "         5.0       0.00      0.00      0.00        18\n",
            "\n",
            "    accuracy                           0.50       294\n",
            "   macro avg       0.31      0.32      0.30       294\n",
            "weighted avg       0.46      0.50      0.46       294\n",
            "\n",
            "Confusion Matrix:\n",
            "[[63 14  4  1  1]\n",
            " [46 72  4  1  0]\n",
            " [19 18 13  0  0]\n",
            " [ 8  9  3  0  0]\n",
            " [11  5  2  0  0]]\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1.\n",
            " 1. 1. 1. 1. 3. 3. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 3. 3. 3. 1. 1. 1. 1.\n",
            " 1. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 2. 2. 2. 1. 1. 1. 1. 3. 3. 3. 3. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 5. 5. 5. 1. 1.\n",
            " 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 3. 3. 3. 3. 3. 3. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 1. 1. 3. 3. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 2. 2. 2. 3. 3. 3. 1. 1. 2. 2. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 1. 3. 1. 1. 3. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 3.\n",
            " 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 4. 1. 1. 1. 3. 3.\n",
            " 3. 1. 1. 3. 3. 3. 3. 3. 3. 3. 3. 3. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 2. 2. 2. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 3. 3. 3. 3. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 1. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 2. 2.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 2.\n",
            " 1. 2. 1. 2. 2. 2. 2. 2. 3. 1. 3. 3. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 4. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
            " 2. 2. 2. 1. 2. 3. 3. 3. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1.\n",
            " 1. 1. 2. 1. 1. 3. 3. 3. 1.]\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_knn_pred = grid_search.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_knn_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Generate and print a classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_knn_pred))\n",
        "\n",
        "# Generate and print a confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_knn_pred))\n",
        "\n",
        "y_prediction = grid_search.predict(preprocessed_test)\n",
        "print(y_prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bIigoLxKYHZ"
      },
      "source": [
        "## 5. Remaining suspects\n",
        "\n",
        "In this section we will identify the potential suspects  according to our new intelligence.\n",
        "\n",
        "Identify which users have a JobRole of 4 or higher on **both** the **Logistic Regression** model and the **Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 29  45  62  98 106 112 126 187 190 233 237 244 263 270 379 401 408 411\n",
            " 429 445 477 535 538 544 561 584 588] [187 188 189 426 650]\n"
          ]
        }
      ],
      "source": [
        "row_numbers_LR = np.where(y_pred >= 4)[0]\n",
        "row_numbers_knn = np.where(y_prediction >= 4)[0]\n",
        "# 'row_numbers' will now contain the indices of rows where the condition is met\n",
        "print(row_numbers_LR,row_numbers_knn)# Your code here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
